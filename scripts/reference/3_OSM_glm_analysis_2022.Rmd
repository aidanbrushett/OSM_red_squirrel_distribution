---
title: "OSM report 2022-2023"
author: "Marissa Dyck"
date: "2024-05-08"
output:
  pdf_document:
    toc: true
  html_document:
    theme: journal
    toc: true
    toc_float: true
---

The first two chunks of this r markdown file after the r setup allow for plot zooming, but it also means that the html file must be opened in a browser to view the document properly. When it knits in RStudio the preview will appear empty but the html when opened in a browser will have all the info and you can click on each plot to Zoom in on it. 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
```

```{css zoom-lib-src, echo = FALSE}
script src = "https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"
```

```{js zoom-jquery, echo = FALSE}
 $(document).ready(function() {
    $('body').prepend('<div class=\"zoomDiv\"><img src=\"\" class=\"zoomImg\"></div>');
    // onClick function for all plots (img's)
    $('img:not(.zoomImg)').click(function() {
      $('.zoomImg').attr('src', $(this).attr('src')).css({width: '100%'});
      $('.zoomDiv').css({opacity: '1', width: 'auto', border: '1px solid white', borderRadius: '5px', position: 'fixed', top: '50%', left: '50%', marginRight: '-50%', transform: 'translate(-50%, -50%)', boxShadow: '0px 0px 50px #888888', zIndex: '50', overflow: 'auto', maxHeight: '100%'});
    });
    // onClick function for zoomImg
    $('img.zoomImg').click(function() {
      $('.zoomDiv').css({opacity: '0', width: '0%'}); 
    });
  });
```

# Before you begin

## Notes

A few notes about this script.

If you are running this with the 2022-2023 data make sure you download the whole (OSM_2022-2023 GitHub repository)[https://github.com/ACMElabUvic/OSM_2022-2023] from the ACMElabUvic GitHub. This will ensure you have all the files, data, and proper folder structure you will need to run this code and associated analyses.

Also make sure you open RStudio through the R project (OSM_2022-2023.Rproj) this will automatically set your working directory to the correct place (wherever you saved the repository) and ensure you don't have to change the file paths for some of the data.

Lastly, if you are looking to adapt this code for a future year of data, you will want to ensure you have run the 2_ACME_landscape_covariate_exploration_script.Rmd with your data as there is much data formatting, cleaning, and restructuring that has to be done before this code will work. *Helpful note: The files are numbered in the order they are used for this analysis*.

If you have question please email the most recent author, currently   

Marissa A. Dyck   
Postdoctoral research fellow    
University of Victoria    
School of Environmental Studies     
Email: [marissadyck17@gmail.com](marissadyck17@gmail.com)      

(*update/add authors as needed*)


## R and RStudio

Before starting you should ensure you have the latest version of R and RStudio downloaded. This code was generated under R version 4.2.3 and with RStudio version 2024.04.2+764.    

You can download R and RStudio [HERE](https://posit.co/download/rstudio-desktop/)   


## R markdown

This script is written in R markdown and thus uses a mix of coding markup languages and R. If you are planning to run this script with new data or make any modifications you will want to be familiar with some basics of R markdown.

Below is an R markdown cheatsheet to help you get started,    
[R markdown cheatsheet](https://www.rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf)    


## Install packages

If you don't already have the following packages installed, use the code below to install them. *NOTE this will not run automatically as eval=FALSE is included in the chunk setup (i.e. I don't want it to run every time I run this code since I have the packages installed).

```{r install packages, eval=FALSE}

install.packages('tidyverse') 
install.packages('ggpubr')
install.packages('corrplot')
install.packages('Hmisc')
install.packages('glmmTMB')
install.packages('MuMIn')
install.packages('TMB', type = 'source')
install.packages('rphylopic')
install.packages('broom')
```

## Load libraries

Then load the packages to your library so they are usable for this session.

```{r libraries, message=FALSE}

library(tidyverse) # data tidying, visualization, and much more; this will load all tidyverse packages, can see complete list using tidyverse_packages()
library(ggpubr) # make modifications to plot for publication (arrange plots)
library(PerformanceAnalytics)    # Used to generate a correlation plot
library(Hmisc) # used to generate histograms for all variables in data frame
library(glmmTMB)      # Constructing GLMMs
library(MuMIn) # for model selection
library(rphylopic) # add animal silhouettes to graphs
library(broom) # extracting odds ratios in a tidy format

```

# Data

## Load detection data

Read in saved and cleaned detection data for the 6 LUs from 2021-2022 and 2022-2023 e.g., the 1_ACME_camera_script_9-2-2024.R.

These are two separate files from the two different fiscal years, so they need to be imported and then merged into one data file for plotting. Since both are stored in the data/processed/ folder we can read them both in as a list with *purrr*.

```{r data}

# detection data
# read in saved and cleaned detection data from the 1_ACME_camera_script_9-2-2024.R 
detections <- file.path('data/processed',
                        
                        c('OSM_ind_det_2021.csv',
                          'OSM_ind_det_2022.csv')) %>% 
  
 map(~.x %>%
        read_csv(.) %>% 
       
       # ensure the array, site, species, and event_id read in as factors
       mutate_if(is.character,
                 as.factor)) %>% 
  
  # give names to each data frame in list
  purrr::set_names('dets_2021',
                   'dets_2022') # R doesn't like when they are just numbers, you can make it work but it's annoying to call the data frame later so I've called them dets_year

# look at data structure
str(detections)
```

## Merge data

Now we need to merge these two files to make plotting them easier. 

They have the same columns so we could just the base R `rbind()` function, but in case there are differences in the columns in the future, let's use the cleaner `dplyr::bind_rows()` function

```{r merge detections}

# Join two years of detection data
detections_merged <- dplyr::bind_rows(detections$dets_2021,
                                      detections$dets_2022)

# check structure of new data
str(detections_merged)
```



## Data checks

Check to make sure the data looks good after merging before moving on.

### Arrays and sites

Let's check that there are the correct number of levels for arrays and sites, there should be 6 arrays and 233 sites (155 from 2022-2023 and 78 from 2021-2022).

```{r check arrays and sites}

# this will provide a summary of the levels
str(detections_merged)

# this will list all unique entries (levels) for each variable
levels(detections_merged$array)
levels(detections_merged$site)

```
Everything looks good.

### NAs

Let's ensure no NAs were introduced where there shouldn't be during the joining process.

```{r check NAs}

# check for NAs introduced during data merge
summary(detections_merged)

```
THe only NAs are in the timediff column which is what we expect since any of the first observations won't have a a value for timediff. If you are confused by this re-visit the 1_ACME_camera_script.

## Summary

Some summaries of the merged detection data

```{r summaries}
focal_species <- c('Black bear',
                      'Caribou',
                      'Coyote',
                      'Fisher',
                      'Grey wolf',
                      'Lynx',
                      'Moose',
                      'Red fox',
                      'White-tailed deer')

focal_mammals <- detections_merged %>% 
  
  filter(species %in% focal_species)
```

## Data Formatting

In order to get plots that have the same formatting as last years' report we have to do a bit of data formatting. First we need to make sure we are including the same relevant species (some were ignored for last years' report or grouped together).

Last years report had the following species

* white-tailed deer
* snowshoe hare
* black bear
* coyote
* red squirrel
* fisher
* unknown
* moose
* lynx
* spruce grouse
* red fox
* striped skunk
* ruffed grouse
* owl
* grey wolf
* domestic dog
* cougar
* raven
* other 
* mule deer

And they grouped all humans except for staff as 'Humans'. Let's look at the species we have in the combined years of data and try to format it the same way.

```{r det species}

detections_merged %>% 
  
  # group by array and species
  group_by(species) %>% 
  summarise(n = n()) %>% 
  
  # sort from greatest to least
  arrange(desc(n)) %>% 
  
  # have R print everything
  print(n = nrow(.))
```
>Hmmm there is one instance of an arctic hare, check that this isn't meant to be a snowshoe hare and fix later if needed. 


Now let's create a new data frame (tibble) to work with for the OSM figure summaries specifically

*I personally would lump all the unknown together and all the birds together but for the sake of consistency with last year's figures we will remove the same entries and keep the birds separate, let's create a vector of entries to drop*

```{r det format}

# create vector of entries to drop for plots
species_drop <- c('Staff',
                  'Unknown deer',
                  'Unknown ungulate',
                  'Unknown canid',
                  'Unknown mustelid',
                  'Other birds',
                  'Arctic hare')

# now we can create the new data frame with some changes consistent w/ choices made for 2021-2022
detections_merged <- detections_merged %>% 
  
  # for summarizing, lets lump all the recreational humans into "Humans"
  mutate(species = recode_factor(species, 
                                 "Snowmobiler" = "Human",
                                 "ATVer" = "Human",
                                 'Hunter' = 'Human')) %>% 
  
  # remove species we don't want to plot
  filter(!species %in% species_drop)

# look at data
str(detections_merged)

```


## Subset data

We will also want to subset the data by landscape unit (LU) and generate a new data frame for each LU to use for plotting

I'm not great at writing loops, so let's see how this shit goes... probably bad but who knows
```{r det subset forloop }

array_frames <- list()

for (i in unique(detections_merged$array)){
  
   #Subset data based on radius
  df <- detections_merged %>%
    filter(array == i)
  
 # list of dataframes
  array_frames <- c(array_frames, list(df))
  
 
}

# inspect one data frame
print(array_frames[[1]]) # this is for LU2
```
... I think this worked


Now let's change names of list items using purrr, couldn't figure out how to name them in the loop, you don't necessarily need to do this because we change the names in the next section, but I like having things named

```{r name array frames}
array_frames <- array_frames %>%

  purrr::set_names('LU02',
                   'LU03',
                   'LU01',
                   'LU13',
                   'LU15',
                   'LU21') 

# inspect each data frame
head(array_frames$LU01)
```


# Detection plots

## Detection data

Now we can apply the same data formatting for each LUs' data frame using purrr.

We want to count the number of independent detections per species per LU to use in the detection plots

```{r det data}

# apply the same formatting to each LU data frame using purrr map
detection_data <- array_frames %>% 
  
  purrr::map(
    ~.x %>% 
      
      # group by species
      group_by(species) %>%
      
      # calculate a column with unique accounts of each species
      mutate(count = n_distinct(event_id)) %>% 
      
      # keep just the columns we need
      select(species, count) %>% 
      
      # keep only unique (distinct) rows so we should be left with one row per species, this helps with plotting later if you don't do it ggplot will try to count and plot each row it's annoying
      distinct()) %>% 
  
  # set names of list objects
  purrr::set_names('Detections LU02',
                   'Detections LU03',
                   'Detections LU01',
                   'Detections LU13',
                   'Detections LU15',
                   'Detections LU21')

```


## Detection plots

Now to graph independent detections for each LU using purrr, this avoids a TON of code repetition needed to plot each one individually

We use `purrr::imap()` instead of `purrr::map()` because imap maintains the variable names in our list (e.g. Detections LU01, Detections LU13, etc.) which we can then use to title each plot.

Within `purrr::imap()` we just paste the code we would use for a single ggplot since all the graphical elements (except the title which we change with the file name [.y]) are the same

```{r det plots}
# create object detection plots which uses the detection_data list (w/ all 4 LUs)
detection_plots <- detection_data %>% 
  
  # use imap instead of map as it allows us to use .y to paste the list element names as the plot titles later
  purrr::imap(
    ~.x %>% 
      
      # now just copy and paste the ggplot code for the detection graphs
      ggplot(.,
             aes(x = reorder(species, count), y = count)) +
      
      # plot as bar graph using geom_col so we don't have to provide a y aesthetic
      geom_col() +
      
      # switch the x and y axis
      coord_flip() +
      
      # add the number of detections at the end of each bar
      geom_text(aes(label = count),
                color = "black",
                size = 3,
                hjust = -0.3,
                vjust = 0.2) +
      
      # label x and y axis with informative titles
      labs(x = 'Species',
           y = 'Number of Independent (30 min) Detections') +
      
      # add title to plot with LU name the .y will take the name of whatever you named each list element in the detection_data list, so make sure this name is what you want on the ggtitle
      ggtitle(.y) +
      
      # set the theme
      theme_classic() +
      theme(plot.title = element_text(hjust = 0.5)))

# view plots, this will print each in it's own window so you have to scroll back in the plot viewer pane to look at each one
detection_plots

```

## Save detection plots

Now we want to save these plots in case we need each individual one (we will combine the detection and naive occ plots into a single figure for each LU later and use those for the OSM report, but we may want these standalone plots later so let's save them while they are here).

We can save all the plots from the purrr iteration above using `purrr::imap`. imap is used instead of map because it allows us to retain the list object names (plot names) to paste as the file name with the .y command.

> IMPORTANT if you are using this code for a future github repo, DO NOT use .tiff as the file extension. This will cause issues when trying to push any changes to the github repo as the files are too large to meet githubs requirements

```{r save det plots, eval=FALSE}

# save plots only use if needed
purrr::imap(
  detection_plots,
  ~ggsave(.x,
             file = paste0("figures/OSM_",
                           .y,
                           '.jpg'), # avoid using .tiff extension in the github repo, those files are too large to push to origin
          dpi = 600,
          width = 11,
          height = 9,
          units = 'in'))

```

# Naive occupancy

## Data

We also need to alter the detection data a bit to use for naive occupancy plots. 

We will use the individual LU detection data like we did before and use `purrr::map()` to apply the dame data formatting to all 4 data frames.

Here we want to calculate the total number of sites in each LU, the number of sites each species was detected at in each LU and then use both those numbers to calculate naive occupancy for each species in each LU

```{r occ data}

# First we need to alter the data frame a bit for these plots, let's create a data frame for each LU (I couldn't figure out how to do this without assigning individual data frames for each UGH)


# apply the same formatting to each data frame using purrr
occupancy_data <- array_frames %>% 
  
  purrr::map(
    ~.x %>% 
      
      # calculate the total number of sites for each LU
      mutate(total_sites = n_distinct(site)) %>% 
      
      # group by species to calculate the number of sites each spp occurred at
      group_by(species) %>% 
  
      # add columns to count the number of sites each spp occurred at and then the naive occupancy
  reframe(count = n_distinct(site),
          naive_occ = count/total_sites,
          ind_det = n_distinct(event_id)) %>% 
  
    # keep just the columns we need
  select(species, naive_occ, ind_det) %>% 
  
    # keep only unique (distinct) rows so we should be left with one row per species, this helps with plotting
  distinct()) %>% 
  
  purrr::set_names('Naive Occupancy LU02',
                   'Naive Occupancy LU03',
                   'Naive Occupancy LU01',
                   'Naive Occupancy LU13',
                   'Naive Occupancy LU15',
                   'Naive Occupancy LU21')
```

## Occupancy plots

Now we can graph naive occupancy for each LU using purrr, and as with the detection plots this saves a massive amount of coding using purrr to run an iteration on the data files and produce four plots at once instead of copying and pasting code for each individually

```{r occ plots}
# create object occupancy_plots which uses the occupancy_data list (w/ all 4 LUs)
occupancy_plots <- occupancy_data %>% 
  
  # use imap instead of map as it allows us to use .y to paste the list element names as the plot titles later
  purrr::imap(
    ~.x %>% 

      # now just copy and paste the ggplot code for the occupancy graphs
      ggplot(.,
             aes(x = fct_reorder(species,
                                 ind_det), # this reorders the species so they match the order of the detection plot which makes it better for viewing when the plots are arranged together in 1 figure for each LU
                 y = naive_occ)) +
      
      # plot as bars using geom_col() which uses stat = 'identity', instead of geom_bar() which will count the rows in each group and plot that instead of naive occ
      geom_col() +
      
      # flip x and y axis 
      coord_flip() +
      
      # add text to end of bars that provides naive occ value
      geom_text(aes(label = round(naive_occ, 2)), 
                size = 3, 
                hjust = -0.3, 
                vjust = 0.2) +
      
      # relabel x and y axis and title
      labs(x = 'Species',
           y = 'Proportion of Sites With At Least One Detection') +
      
      # set plot title using .y (name of list object)
      ggtitle(.y) +
      
      # set. theme elements
      theme_classic()+
      theme(plot.title = element_text(hjust = 0.5)))

# view plots
occupancy_plots
```

## Save occupancy plots

As with the detection plots, we might want these individual plots later for something so we can use `purrr::imap()` to save them to the figures folder

Again avoid using the .tiff extension in github

```{r save occ plots, eval=FALSE}

# save plots 
purrr::imap(
  occupancy_plots,
  ~ggsave(.x,
          file = paste0("figures/OSM_",
                        .y,
                        '.jpg'), # avoid using .tiff extension in the github repo, those files are too large to push to origin
          dpi = 600,
          width = 11,
          height = 9,
          units = 'in'))

```

# Final combined plots for report

The previous year's report had a figure for each LU with the detections plot on the top and the occupancy plot on the bottom so we will recreate these for this year using `ggarrange()`.

Unfortunately I could not figure out how to do this in purrr to reduce coding but luckily it isn't too much repetition


```{r combine plots}

# not sure I know how to do the following section in purrr just yet, but we've saved a ton of coding so far and it doesn't take much to arrange each of these individually

# LU2
LU02_det_occ_plots <- ggarrange(detection_plots$`Detections LU02`, 
                               occupancy_plots$`Naive Occupancy LU02`,
                               labels = c("A", "B"),
                               nrow = 2)

# view plot
LU02_det_occ_plots


# LU3
LU03_det_occ_plots <- ggarrange(detection_plots$`Detections LU03`, 
                               occupancy_plots$`Naive Occupancy LU03`,
                               labels = c("A", "B"),
                               nrow = 2)

# view plot
LU03_det_occ_plots

# LU1

# arrange the plots so each LU has a figure with detections on top and naive occ on bottom
LU01_det_occ_plots <- ggarrange(detection_plots$`Detections LU01`, 
                               occupancy_plots$`Naive Occupancy LU01`,
                               labels = c("A", "B"),
                               nrow = 2)

# view plot
LU01_det_occ_plots

# LU13

# arrange the plots so each LU has a figure with detections on top and naive occ on bottom
LU13_det_occ_plots <- ggarrange(detection_plots$`Detections LU13`, 
                                occupancy_plots$`Naive Occupancy LU13`,
                               labels = c("A", "B"),
                               nrow = 2)

# view plot
LU13_det_occ_plots


# LU15

# arrange the plots so each LU has a figure with detections on top and naive occ on bottom
LU15_det_occ_plots <- ggarrange(detection_plots$`Detections LU15`, 
                                occupancy_plots$`Naive Occupancy LU15`,
                                labels = c("A", "B"),
                                nrow = 2)

# view plot
LU15_det_occ_plots


# LU21

# arrange the plots so each LU has a figure with detections on top and naive occ on bottom
LU21_det_occ_plots <- ggarrange(detection_plots$`Detections LU21`, 
                                occupancy_plots$`Naive Occupancy LU21`,
                                labels = c("A", "B"),
                                nrow = 2)

# view plot
LU21_det_occ_plots

```

We can however, save all the figures again using purrr

```{r save combine plots, eval=FALSE}

# save all figures at once using purrr
final_det_occ_plots <- list(LU02_det_occ_plots,
                            LU03_det_occ_plots,
                            LU01_det_occ_plots,
                            LU13_det_occ_plots,
                            LU15_det_occ_plots,
                            LU21_det_occ_plots) %>% 
  

  purrr::set_names('LU02_det_occ_plots',
                   'LU03_det_occ_plots',
                   'LU01_det_occ_plots',
                   'LU13_det_occ_plots',
                   'LU15_det_occ_plots',
                   'LU21_det_occ_plots') %>% 
  
  purrr::imap(
    ~ggsave(.x,
            file = paste0("figures/OSM_",
                          .y,
                          '.jpg'), # avoid using .tiff extension in the github repo, those files are too large to push to origin
            dpi = 600,
            width = 12,
            height = 15,
            units = 'in'))

```

## Finish with detection data

Before proceeding let's clear the objects currently in our environment since we don't need them for the analysis

```{r clear env}
rm(list = ls(all.names = TRUE))
```

# Global Analysis prep

Now we can start the analysis prep.

First we need to read in the proportional detection (response metrics) and covariate (explanatory metrics) data files for all 6 LUs (fiscal years 2021-2022 and 2022-2023)


## Response metrics

### Read in data files

We haven't joined the response metrics from 2021-2022 and 2022-2023 in any previous scripts yet, so let's read those in using *purrr* and then join them and take a look at the data to make sure it looks good. 

```{r}
# response metric (proportional detections from the from the ACME_camera_script_9-2-2024.R or .Rmd)

prop_detections <-  file.path('data/processed',
                         
                         c('OSM_proportional_detections_2021.csv',
                           'OSM_proportional_detections_2022.csv')) %>% 
  
  map(~.x %>%
        read_csv(.,
                 
                  # set the column types to read in correctly
                 col_types = cols(site = col_factor(),
                                  .default = col_number()))) %>% 
  
  # give names to each data frame in list
  purrr::set_names('prop_dets_2021',
                   'prop_dets_2022') # R doesn't like when they are just numbers, you can make it work but it's annoying to call the data frame later so I've called them prop_dets_year

# check variable structure
str(prop_detections)


```

### Merge data files 

Now we need to merge the two data files for analysis. We can do this with *dplyr*.

```{r merge prop dets}

# merge the proportional detections files so there are rows for both fiscal years
prop_dets_all <- dplyr::bind_rows(prop_detections$prop_dets_2021,
                                  prop_detections$prop_dets_2022)

print(prop_dets_all)
```

### Format data

This looks good except since there were no wolverines in the first fiscal year of monitoring (LU02 and LU03) those columns have NAs for both arrays, we want to replace those NAs with Zeros and move the wolverine column to the correct location

Let's do that now.

```{r format prop dets all}

prop_dets_all <- prop_dets_all %>% 
  
   # replace NAs introduced from joining data to zeros
  replace(is.na(.),
          0) %>% 
  
  # relocate wolverine column
  relocate(.,
           wolverine,
           .after = caribou)

# check data
head(prop_dets_all)

```
Looks good!

### Save data

Let's save the merged and formatted detection data from 2021 and 2022 for future use

```{r save joined det data}

write_csv(prop_dets_all,
          'data/processed/OSM_proportional_detections_merged_2021_2022.csv')
```



## Covariates

In the previous script, 2_ACME_landscape_covariate_exploration_script.Rmd we joined the two fiscal years of data and grouped the covariates for analysis and saved this data as a csv file, so we can read in this file now and we shouldn't have to do any further formatting at the moment

### Read data

We will check the data structure after reading in the file just to make sure everything looks good.
```{r read covs}

covariates_all <- read_csv('data/processed/OSM_covariates_grouped_2021_2022.csv',
                           
                           # set the column types to read in correctly
                           col_types = cols(array = col_factor(),
                                            camera = col_factor(),
                                            site = col_factor(),
                                            buff_dist = col_factor(),
                                            .default = col_number()))

str(covariates_all)

```
Everything looks good!

###Subset data by buffer

We do need to subset the data so we have separate data frames for each buffer width to work with in the analysis **AND** to explore correlations between variables at each buffer width, as these may very with spatial scales

Let's use a for loop to subset the data, thanks Andrew!
```{r subset data}
buffer_frames <- list()

for (i in unique(covariates_all$buff_dist)){
  
  print(i)
  
  # Subset data based on radius
  df <- covariates_all %>%
    filter(buff_dist == i)
  
  # list of dataframes
  buffer_frames <-c (buffer_frames, list(df))
}

# name list objects so we can extract names for plotting 

buffer_frames <- buffer_frames %>% 
  
  # absurdly long way to do this but for sake of time fuck it
  purrr::set_names('250 meter buffer',
                   '500 meter buffer',
                   '750 meter buffer',
                   '1000 meter buffer',
                   '1250 meter buffer',
                   '1500 meter buffer',
                   '1750 meter buffer',
                   '2000 meter buffer',
                   '2250 meter buffer',
                   '2500 meter buffer',
                   '2750 meter buffer',
                   '3000 meter buffer',
                   '3250 meter buffer',
                   '3500 meter buffer',
                   '3750 meter buffer',
                   '4000 meter buffer',
                   '4250 meter buffer',
                   '4500 meter buffer',
                   '4750 meter buffer',
                   '5000 meter buffer')
```

Now we have a list with data frames for each buffer width which we can work with later. 

### Add response metric

Now that we have the covariate data formatted we need to add the response metric (monthly proportional presence/absence) to the data frames

```{r response metric}

osm_final_df_2021_2022 <- buffer_frames %>% 
  
  purrr::map(
    ~.x %>% 
      
      left_join(prop_dets_all,
                by = 'site'))
```

### Finish with data formatting

Let's remove the objects we no longer need from the environment to keep our work space clean

```{r rm data}
rm(covariates_all,
   prop_detections,
   df,
   i)
```

# Global Analysis

Now we are going to run a global model which includes all HFI and LC variables that at first glance (will do a more thorough check later) seem to have enough data to include as covariates for each buffer width, and then we will compare these models see which buffer width best fit the data  for each species. After that we will optimize models so they don't includes any variables that are highly correlated.

> Edit: we added subset analsyis (anthropogenic and landscape) where we subset the data into anthropogenic features (HFI) and landscape (landcover classes) to see how optimum buffer size was influenced based on the type of variables included in the models. For these subset analyses we also looked more closely at which variables were correlated and have adjusted the global models accordingly (i.e. dropped/merged the same variables) to make them more accurate and comparable to the subset models. If there are variables commented out of the models, these were used in the initial run-through of the analysis but were dropped in the subset models so I've dropped them accordingly in a re-run of the global models. 

This almost means we have to add one quick data formatting step which wasn't here in the initial run through of the data

```{r added data formatting}

osm_final_df_2021_2022 <- osm_final_df_2021_2022 %>% 
  
  # use purr so all changes are made to all data frames
  purrr::map(
    ~.x %>% 
      
  # mutate data to merge variables that were correlated and similar enough to count as one for the purposes of this analysis (full explanation in subset analysis prep section)
  mutate(pipeline_transmission_lines = pipeline + transmission_lines,
         lc_forest = lc_coniferous + lc_broadleaf + lc_mixed))

# view structure of one data frame
str(osm_final_df_2021_2022$`250 meter buffer`)
```


We don't need to do ALL the species since many don't have enough data.

> Refer to the 1_ACME_camera_script_9-2-2024.html or .Rmd the plot for proportional monthly detections should provide info on which species we have enough data for, can be found under Response metrics/3.Proportion monthly detections

A brief look at this fig indicates that we have enough for all the mammals in the prop_detections data frame **except**

* cougar    
* wolverine  
* caribou??? (may have enough, may not)


## Black bear 

> there is probably a way to shorten the following code to select particular species, I saw Andrew's for loop in the draft script he wrote but couldn't quite figure out how to adapt it to my purposes with the data formatted the way I have it, so I did this instead, maybe we can merge approaches later to clean this up if deemed necessary? But it certainly functions for now and is understandable... I think. 


### Global models

Let's start with bears and use purrr to create a global model for every buffer distance

Recall `purrr::map()` is magical for iterations and will apply all the functions within the `map()` function to each item of the list supplied before the the `map()` function.
```{r black bear global model}

# create models for black bears at each buffer size
black_bear_mods <- osm_final_df_2021_2022 %>%

  # use purrr map to run the same functions for all buffer sizes ((all objects in list))
  purrr::map(
    ~.x %>%

      # glmmTMB function let's us run the proportional binomial model using cbind to combine the present and absent columns for each species
     glmmTMB::glmmTMB(cbind(black_bear, absent_black_bear) ~
                        
                        # HFI
                        scale(harvest) +
                        # scale(pipeline) +
                        # scale(roads) +
                        scale(seismic_lines) +
                        scale(seismic_lines_3D) +
                        scale(trails) +
                        # scale(transmission_lines) +
                        # scale(veg_edges) +
                        scale(wells) +
                        scale(osm_industrial) +
                        scale(pipeline_transmission_lines) +
                        
                        # VEG covariates in numerical order
                        scale(lc_grassland) +
                        # scale(lc_coniferous) +
                        # scale(lc_broadleaf) +
                        # scale(lc_mixed) +
                        scale(lc_developed) +
                        # scale(lc_shrub) +
                        scale(lc_forest) +
                        
                        # Random effect of array
                        (1|array),
                   data = .,
                   family = 'binomial'))


```


#### Model selection

We will use the `model.sel()` function from the *MuMIn* package to compare the global models for each buffer width and see which buffer fits the black bear data best

```{r black bear mod selection}

# run model selection and save the results as a tibble for graphing use later
black_bear_global_model.sel <- model.sel(black_bear_mods) %>% 
  
  as.data.frame() %>% 
  
  rownames_to_column(var = 'Model')  %>%
  
  mutate(Dataset = deparse(substitute(osm_final_df_2021_2022)))

# look at model selection results
black_bear_global_model.sel

```

Looks like the smallest buffer (250) fits the data best for black bears.

> Note about re-run global models: when we removed the correlated variables the top model satyed the same (250m) but the weight increased (from 0.159 to 0.678)

Let's look at this model closer

#### Model summary

Since we aren't interpreting the magnitude and direction of effect for individual variables in the model as you normally would, the model summary serves primarily to see that there are no issues with the top model (convergence issues, large SE, etc.) that could cause us to quetion the results of the model.sel() function.

```{r black bear 250 summary}

summary(black_bear_mods$`250 meter buffer`)
```
Nothing looks fishy in the model summary for now, we will look at this more closely once we have a true top model.

#### Code to remove a model

> At one point the 250 meter buffer was giving us issues so we had to remove it. After re-extracting the data and re-doing some data formatting this is no longer an issue but I've saved the code here in case it's needed in the future

```{r code to remove model, eval = FALSE}

# create models for black bears at each buffer size
black_bear_mods_no250 <- osm_final_df_2021_2022 %>%

# remove 250 meter buffer width
  purrr::discard_at('250 meter buffer') %>% 

  # use purrr map to fun the same functions for all buffer sizes ((all objects in list))
  purrr::map(
    ~.x %>%

      # glmmTMB function let's us run the proportional binomial model using cbind to combine the present and absent columns for each species
     glmmTMB::glmmTMB(cbind(black_bear, absent_black_bear) ~
                        
                        # HFI
                        scale(harvest) +
                        scale(pipeline) +
                        scale(roads) +
                        scale(seismic_lines) +
                        scale(seismic_lines_3D) +
                        scale(trails) +
                        scale(transmission_lines) +
                        scale(veg_edges) +
                        scale(wells) +
                        scale(osm_industrial) +
                        
                        # VEG covariates in numerical order
                        scale(lc_grassland) +
                        scale(lc_coniferous) +
                        scale(lc_broadleaf) +
                        scale(lc_mixed) +
                        scale(lc_developed) +
                        scale(lc_shrub) +
                        
                        # Random effect of array
                        (1|array),
                   data = .,
                   family = 'binomial'))
```


### Subset models

> NOTE this code was not used for publication but was an initial idea for how we could further use the data. We only explored subset models for Bears thus far, but have left the headings for the other species in case we want to add in these subset models later


#### Autocorrelation 250m

Before we can develop model subsets we need to see what variables can be included in the same model at this buffer width.

Let's use the `chart.Correlation()` function in the *Performance Analytics* package to look at this.

```{r cor 250, warning=FALSE}

buffer_frames$`250 meter buffer` %>% 
  
  select_if(is.numeric) %>% 
  
   # use chart.correlation 
      chart.Correlation(.,
                        histogram = TRUE, 
                        method = "pearson")

mtext('250 meter buffer', side = 3, line = 3)
  
```
> You can click on this fig to zoom in!

List of correlated variables:   

* pipeline & transmission_lines 0.53    
* roads & veg_edges 0.71
* roads & lc_developed 0.57

#### Model list 

Let's create another global model without these correlated variables. I'm going to select transmission_lines over pipeline because the summary from earlier showed transmission lines had larger effect on black bear presence, and I'm going to choose to keep roads instead of veg edges and the developed landcover class because we are interested in the effect of roads more than these other two variables.

```{r black bear mods 250}

# global model w/ non-correlated variables
bear_global_250 <-  glmmTMB::glmmTMB(cbind(black_bear, absent_black_bear) ~
                        
                        # HFI
                        scale(harvest) +
                        scale(roads) +
                        scale(seismic_lines) +
                        scale(seismic_lines_3D) +
                        scale(trails) +
                        scale(transmission_lines) +
                        scale(wells) +
                        scale(osm_industrial) +
                        
                        # VEG covariates in numerical order
                        scale(lc_grassland) +
                        scale(lc_coniferous) +
                        scale(lc_broadleaf) +
                        scale(lc_mixed) +
                        scale(lc_shrub) +
                        
                        # Random effect of array
                        (1|array),
                   data = osm_final_df_2021_2022$`250 meter buffer`,
                   family = 'binomial')

# null model to compare
bear_null_250 <- glmmTMB::glmmTMB(cbind(black_bear, absent_black_bear) ~ 1 +
                        
                        # Random effect of array
                        (1|array),
                   data = osm_final_df_2021_2022$`250 meter buffer`,
                   family = 'binomial')

# second model is based on linear features providing easier movement through boreal forest
bear_linear_250 <- glmmTMB::glmmTMB(cbind(black_bear, absent_black_bear) ~
                        
                        # HFI
                        scale(roads) +
                        scale(seismic_lines) +
                        scale(seismic_lines_3D) +
                        scale(trails) +
                        scale(transmission_lines) +
                        
                        # Random effect of array
                        (1|array),
                   data = osm_final_df_2021_2022$`250 meter buffer`,
                   family = 'binomial')
```


#### Model selection

 Now let's look at a model selection table with our subset models.
 
```{r black bear mod selection 2}

model.sel(bear_global_250,
          bear_null_250,
          bear_linear_250)

```

Looks like the linear feature model is best, SO FAR

###  Top model

250 meter buffer - linear features

#### Summary

```{r bear summary}

summary(bear_linear_250)
```

#### Odds ratios

Let's extract the odds ratios for the top model so we can plot them for data vis later.


```{r bear odds ratios}
bear_model_odds <- bear_linear_250 %>% 

  # extract the coefficients and upper and lower CI
      confint() %>% 
 
      # format resulting object as a tibble data frame
      as_tibble() %>%
  
      
      # add a column where we can put the feature names
      rowid_to_column() %>% 
      
      # rename the columns for plotting
      rename('lower' = `2.5 %`,
             'upper' = `97.5 %`,
             'estimate' = Estimate,
             'feature' = rowid) %>% 
      
      # rename the entries to features, need to look at the order the features are in from the model summary and ensure it matches
      mutate(feature = as.factor(feature),
             feature = recode(feature,
                              '1' = 'intercept',
                              '2' = 'roads',
                              '3' = 'seismic_lines',
                              '4' = 'seismic_lines_3D',
                              '5' = 'trails',
                              '6' = 'transmission_lines',
                              '7' = 'intercept_array')) %>% 
  
  # remove intercepts
  filter(!grepl('intercept',
                feature))
```

#### Plot odds ratios

First let's get a silhouette for this graphy from phylopic

```{r bear phylopic}

black_bear_img <- get_phylopic(get_uuid(name = 'Ursus americanus'))
```


Now let's use ggplot to plot the odds ratios for each feature in the top model

```{r plot bear odds}

# provide data and mapping aesthetics
ggplot(bear_model_odds, aes(x = feature, 
                          y = estimate)) +
  
   geom_errorbar(aes(ymin = lower, 
                     ymax = upper),
                width = 0.4,
                linewidth = 0.5,
                position = position_dodge(width = 0.9)) +
  
   geom_hline(yintercept = 0, linetype = "dashed") +
  
  labs(y = 'Odds ratio') +
  
  scale_x_discrete(labels = c('Roads',
                              'Seismic Lines',
                              '3D Seismic Lines',
                              'Trails',
                              'Transmission Lines')) +
  
  add_phylopic(black_bear_img, 
               x = 5.3,
               y = 0.2,
               ysize = 0.05) +
  
  theme_classic() +
  
  theme(axis.title.x = element_blank(),
        axis.text.x = element_text(angle = 90,
                                   hjust = 1),
        axis.title = element_text(size = 16),
        axis.text = element_text(size = 14))
```

Let's repeat this process for each species that we have enough data for.

## Caribou

We may or may not have enough data for caribou but let's try it at least for this preliminary report

We can use the same code from black bears (above) to run global models for each buffer width 

And in the same chunk to save time let's also run the `model.sel()` function

### Global models
```{r caribou mods}

caribou_mods <- osm_final_df_2021_2022 %>%
  
  # use purrr map to make global models for all other buffer sizes
  purrr::map(
    ~.x %>%

     glmmTMB::glmmTMB(cbind(caribou, absent_caribou) ~
                        
                        # HFI
                        scale(harvest) +
                        # scale(pipeline) +
                        # scale(roads) +
                        scale(seismic_lines) +
                        scale(seismic_lines_3D) +
                        scale(trails) +
                        # scale(transmission_lines) +
                        # scale(veg_edges) +
                        scale(wells) +
                        scale(osm_industrial) +
                        scale(pipeline_transmission_lines) +
                        
                        # VEG covariates in numerical order
                        scale(lc_grassland) +
                        # scale(lc_coniferous) +
                        # scale(lc_broadleaf) +
                        # scale(lc_mixed) +
                        scale(lc_developed) +
                        # scale(lc_shrub) +
                        scale(lc_forest) +
                        
                        # Random effect of array
                        (1|array),
                   data = .,
                   family = 'binomial'))

# run model selection and save the results as a tibble for graphing use later
caribou_global_model.sel <- model.sel(caribou_mods) %>% 
  
  as.data.frame() %>% 
  
  rownames_to_column(var = 'Model')  %>%
  
  mutate(Dataset = deparse(substitute(osm_final_df_2021_2022)))

# look at model selection results
caribou_global_model.sel
```

We get a warning that there are some model convergence problems, I expect this is because we don't have enough data for caribou, so we may choose to remove the caribou results from the manuscript or provide that caveat.

For now let's examine the top buffer width and see if the model seems reasonable.

> Note about re-run global models: when we re-ran the global models with dropped correlated variables our top model for caribou does change (3000m to 1000m) which now matches the top model for anthropogenic features, this could be because there are more anthro features in the global models and/or because of lack of data/model convergence issues. If we see this same trend with other global models it will be worth mentioning as a caveat in the discussion.

#### Model summary 1000m

Let's take a closer look at the top model summary
```{r caribou 1000 summary}

summary(caribou_mods$`1000 meter buffer`)
```

There's nothing that catches my eye immediately as being sus about this particular model so it may not have been one with convergence issues. We will keep it in report for now

### Subset Models

Add later if deemed necessary.


## Coyote

### Global models
```{r coyote mods}

coyote_mods <- osm_final_df_2021_2022 %>%
  
  # use purrr map to make global models for all other buffer sizes
  purrr::map(
    ~.x %>%

     glmmTMB::glmmTMB(cbind(coyote, absent_coyote) ~
                        
                        # HFI
                        scale(harvest) +
                        # scale(pipeline) +
                        # scale(roads) +
                        scale(seismic_lines) +
                        scale(seismic_lines_3D) +
                        scale(trails) +
                        # scale(transmission_lines) +
                        # scale(veg_edges) +
                        scale(wells) +
                        scale(osm_industrial) +
                        scale(pipeline_transmission_lines) +
                        
                        # VEG covariates in numerical order
                        scale(lc_grassland) +
                        # scale(lc_coniferous) +
                        # scale(lc_broadleaf) +
                        # scale(lc_mixed) +
                        scale(lc_developed) +
                        # scale(lc_shrub) +
                        scale(lc_forest) +
                        
                        # Random effect of array
                        (1|array),
                   data = .,
                   family = 'binomial'))


# run model selection and save the results as a tibble for graphing use later
coyote_global_model.sel <- model.sel(coyote_mods) %>% 
  
  as.data.frame() %>% 
  
  rownames_to_column(var = 'Model')  %>%
  
  mutate(Dataset = deparse(substitute(osm_final_df_2021_2022)))

# look at model selection results
coyote_global_model.sel
```

> Note about re-run global models: when we re-ran the global models with dropped correlated variables our top model for coyote did change (2250-5000). As with caribou this result is also more similar to the top anthro model (4750m)

#### Model summary 5000m

Let's get the model summary for this model

```{r coyote 5000 summary}

summary(coyote_mods$`5000 meter buffer`)
```
Everything looks good here

### Subset models

Add later if deemed necessary.



## Fisher

### Global models
```{r fisher mods}

fisher_mods <- osm_final_df_2021_2022 %>%
  
  # use purrr map to make global models for all other buffer sizes
  purrr::map(
    ~.x %>%

     glmmTMB::glmmTMB(cbind(fisher, absent_fisher) ~
                        
                        # HFI
                        scale(harvest) +
                        # scale(pipeline) +
                        # scale(roads) +
                        scale(seismic_lines) +
                        scale(seismic_lines_3D) +
                        scale(trails) +
                        # scale(transmission_lines) +
                        # scale(veg_edges) +
                        scale(wells) +
                        scale(osm_industrial) +
                        scale(pipeline_transmission_lines) +
                        
                        # VEG covariates in numerical order
                        scale(lc_grassland) +
                        # scale(lc_coniferous) +
                        # scale(lc_broadleaf) +
                        # scale(lc_mixed) +
                        scale(lc_developed) +
                        # scale(lc_shrub) +
                        scale(lc_forest) +
                        
                        # Random effect of array
                        (1|array),
                   data = .,
                   family = 'binomial'))

# run model selection and save the results as a tibble for graphing use later
fisher_global_model.sel <- model.sel(fisher_mods) %>% 
  
  as.data.frame() %>% 
  
  rownames_to_column(var = 'Model')  %>%
  
  mutate(Dataset = deparse(substitute(osm_final_df_2021_2022)))

# look at model selection results
fisher_global_model.sel
```

> Note about re-run global models: when we re-ran the global models with dropped correlated variables our top model for fisher did not change but the weight did increase (0.266 - 0.526)


#### Model summary 1000m

Let's print the summary for this model

```{r fisher 1000 summary}

summary(fisher_mods$`1000 meter buffer`)
```
Everything looks good

### Subset models

Add later if deemed necessary.


## Grey wolf

### Global models

```{r wolf mods}

wolf_mods <- osm_final_df_2021_2022 %>%
  
  # use purrr map to make global models for all other buffer sizes
  purrr::map(
    ~.x %>%

     glmmTMB::glmmTMB(cbind(grey_wolf, absent_grey_wolf) ~
                        
                        # HFI
                        scale(harvest) +
                        # scale(pipeline) +
                        # scale(roads) +
                        scale(seismic_lines) +
                        scale(seismic_lines_3D) +
                        scale(trails) +
                        # scale(transmission_lines) +
                        # scale(veg_edges) +
                        scale(wells) +
                        scale(osm_industrial) +
                        scale(pipeline_transmission_lines) +
                        
                        # VEG covariates in numerical order
                        scale(lc_grassland) +
                        # scale(lc_coniferous) +
                        # scale(lc_broadleaf) +
                        # scale(lc_mixed) +
                        scale(lc_developed) +
                        # scale(lc_shrub) +
                        scale(lc_forest) +
                        
                        # Random effect of array
                        (1|array),
                   data = .,
                   family = 'binomial'))

# run model selection and save the results as a tibble for graphing use later
wolf_global_model.sel <- model.sel(wolf_mods) %>% 
  
  as.data.frame() %>% 
  
  rownames_to_column(var = 'Model')  %>%
  
  mutate(Dataset = deparse(substitute(osm_final_df_2021_2022)))

# look at model selection results
wolf_global_model.sel
```

> Note about re-run global models: when we re-ran the global models with dropped correlated variables our top model for wolf did change (500 - 3500), as with coyote and caribou this is more similar to top anthro modelthan it was before AND actually the same as the landscape model

#### Model summary 3500m

Let's get the model summary for this model

```{r wolf 3500 summary}

summary(wolf_mods$`3500 meter buffer`)
```


### Subset models

Add later if deemed necessary.



## Lynx

###  Global models

```{r lynx mods}

lynx_mods <- osm_final_df_2021_2022 %>%
  
  # use purrr map to make global models for all other buffer sizes
  purrr::map(
    ~.x %>%

     glmmTMB::glmmTMB(cbind(lynx, absent_lynx) ~
                        
                        # HFI
                        scale(harvest) +
                        # scale(pipeline) +
                        # scale(roads) +
                        scale(seismic_lines) +
                        scale(seismic_lines_3D) +
                        scale(trails) +
                        # scale(transmission_lines) +
                        # scale(veg_edges) +
                        scale(wells) +
                        scale(osm_industrial) +
                        scale(pipeline_transmission_lines) +
                        
                        # VEG covariates in numerical order
                        scale(lc_grassland) +
                        # scale(lc_coniferous) +
                        # scale(lc_broadleaf) +
                        # scale(lc_mixed) +
                        scale(lc_developed) +
                        # scale(lc_shrub) +
                        scale(lc_forest) +
                        
                        # Random effect of array
                        (1|array),
                   data = .,
                   family = 'binomial'))

# run model selection and save the results as a tibble for graphing use later
# run model selection and save the results as a tibble for graphing use later
lynx_global_model.sel <- model.sel(lynx_mods) %>% 
  
  as.data.frame() %>% 
  
  rownames_to_column(var = 'Model')  %>%
  
  mutate(Dataset = deparse(substitute(osm_final_df_2021_2022)))

# look at model selection results
lynx_global_model.sel
```

> Note about re-run global models: when we re-ran the global models with dropped correlated variables our top model for lynx did change (1250 - 250), as with others this is more similar to top anthro model (acutally the same as anthro model).

#### Model summary 250m

Let's get the model summary

```{r lynx 250 summary}

summary(lynx_mods$`250 meter buffer`)
```
Everything looks good so far

### Subset models

Add later if deemed necessary.




## Moose

### Global model

```{r moose mods}

moose_mods <- osm_final_df_2021_2022 %>%
  
  # use purrr map to make global models for all other buffer sizes
  purrr::map(
    ~.x %>%

     glmmTMB::glmmTMB(cbind(moose, absent_moose) ~
                        
                        # HFI
                        scale(harvest) +
                        # scale(pipeline) +
                        # scale(roads) +
                        scale(seismic_lines) +
                        scale(seismic_lines_3D) +
                        scale(trails) +
                        # scale(transmission_lines) +
                        # scale(veg_edges) +
                        scale(wells) +
                        scale(osm_industrial) +
                        scale(pipeline_transmission_lines) +
                        
                        # VEG covariates in numerical order
                        scale(lc_grassland) +
                        # scale(lc_coniferous) +
                        # scale(lc_broadleaf) +
                        # scale(lc_mixed) +
                        scale(lc_developed) +
                        # scale(lc_shrub) +
                        scale(lc_forest) +
                        
                        # Random effect of array
                        (1|array),
                   data = .,
                   family = 'binomial'))

# run model selection and save the results as a tibble for graphing use later
moose_global_model.sel <- model.sel(moose_mods) %>% 
  
  as.data.frame() %>% 
  
  rownames_to_column(var = 'Model')  %>%
  
  mutate(Dataset = deparse(substitute(osm_final_df_2021_2022)))

# look at model selection results
moose_global_model.sel
```

> Note about re-run global models: when we re-ran the global models with dropped correlated variables our top model for moose did not change but the weight did increase (0.504 - 0.941). This top model is the same as the landscape model.

#### Model summary 250m

Let's get the model summary

```{r moose 250 summary}

summary(moose_mods$`250 meter buffer`)
```
Looks good for now

### Subset models

Add later if deemed necessary



## Red fox

### Global models

```{r fox mods}
fox_mods <- osm_final_df_2021_2022 %>%
  
  # use purrr map to make global models for all other buffer sizes
  purrr::map(
    ~.x %>%

     glmmTMB::glmmTMB(cbind(red_fox, absent_red_fox) ~
                        
                        # HFI
                        scale(harvest) +
                        # scale(pipeline) +
                        # scale(roads) +
                        scale(seismic_lines) +
                        scale(seismic_lines_3D) +
                        scale(trails) +
                        # scale(transmission_lines) +
                        # scale(veg_edges) +
                        scale(wells) +
                        scale(osm_industrial) +
                        scale(pipeline_transmission_lines) +
                        
                        # VEG covariates in numerical order
                        scale(lc_grassland) +
                        # scale(lc_coniferous) +
                        # scale(lc_broadleaf) +
                        # scale(lc_mixed) +
                        scale(lc_developed) +
                        # scale(lc_shrub) +
                        scale(lc_forest) +
                        
                        # Random effect of array
                        (1|array),
                   data = .,
                   family = 'binomial'))


# run model selection and save the results as a tibble for graphing use later
fox_global_model.sel <- model.sel(fox_mods) %>% 
  
  as.data.frame() %>% 
  
  rownames_to_column(var = 'Model')  %>%
  
  mutate(Dataset = deparse(substitute(osm_final_df_2021_2022)))

# look at model selection results
fox_global_model.sel

```

> Note about re-run global models: when we re-ran the global models with dropped correlated variables our top model for fox did not change but the weight dropped (0.855 - 0.367). This top model is the same as the landscape model.

#### Model summary 4750m

Let's get the model summary

```{r fox summary 4750}

summary(fox_mods$`4750 meter buffer`)
```

Looks good so far

### Subset Models

Add later if deemed necessary.


## White-tailed deer

### Global models

```{r deer mods}

deer_mods <- osm_final_df_2021_2022 %>%
  
  # use purrr map to make global models for all other buffer sizes
  purrr::map(
    ~.x %>%

      # have to include the `` around the white-tailed_deer or R won't recognize it as a variable because of the -
     glmmTMB::glmmTMB(cbind(`white-tailed_deer`, `absent_white-tailed_deer`) ~
                        
                        # HFI
                        scale(harvest) +
                        # scale(pipeline) +
                        # scale(roads) +
                        scale(seismic_lines) +
                        scale(seismic_lines_3D) +
                        scale(trails) +
                        # scale(transmission_lines) +
                        # scale(veg_edges) +
                        scale(wells) +
                        scale(osm_industrial) +
                        scale(pipeline_transmission_lines) +
                        
                        # VEG covariates in numerical order
                        scale(lc_grassland) +
                        # scale(lc_coniferous) +
                        # scale(lc_broadleaf) +
                        # scale(lc_mixed) +
                        scale(lc_developed) +
                        # scale(lc_shrub) +
                        scale(lc_forest) +
                        
                        # Random effect of array
                        (1|array),
                   data = .,
                   family = 'binomial'))


# run model selection and save the results as a tibble for graphing use later
deer_global_model.sel <- model.sel(deer_mods) %>% 
  
  as.data.frame() %>% 
  
  rownames_to_column(var = 'Model')  %>%
  
  mutate(Dataset = deparse(substitute(osm_final_df_2021_2022)))

# look at model selection results
deer_global_model.sel
```

> Note about re-run global models: when we re-ran the global models with dropped correlated variables our top model for deer did not change but the weight dropped (0.974 - 0.234). This top model is the same as the landscape model.

#### Model summary 1500m

Let's get the model summary

```{r deer 1500 summary}

summary(deer_mods$`1500 meter buffer`)
```
Looks okay for now

### Subset models

Add later if deemed necessary.


## Top buffers

For convenience here is a list of the top buffer widths for each species

**Initial run**   
* Black bear - 250m   
* Caribou - 3000m   
* Coyote - 2250m    
* Fisher - 1000m    
* Grey wolf - 500m    
* Lynx - 1250m    
* Moose - 250m    
* Red fox - 4750    
* White-tailed deer - 1500m  

**Re-run** (without correlated variables)        
* Black bear - 250m   
* Caribou - 1000m   
* Coyote - 5000m    
* Fisher - 1000m    
* Grey wolf - 3500m   
* Lynx - 250m   
* Moose - 250m    
* Red fox - 4750m   
* White-tailed deer - 1500m   



I also want to create a data frame with the model.sel outputs from each species so I can plot these results later

```{r global model.sel data}

# provide list of model.sel data frames from global analysis

global_model.sel_data <- list(
  bear = black_bear_global_model.sel,
  caribou = caribou_global_model.sel,
  coyote = coyote_global_model.sel,
  fisher = fisher_global_model.sel,
  wolf = wolf_global_model.sel,
  lynx = lynx_global_model.sel,
  moose = moose_global_model.sel,
  fox = fox_global_model.sel,
  deer = deer_global_model.sel
) %>% 
  
  # use purrr to combine data and extract species names to use as a column
  map_dfr(~.x %>% 
            
            mutate(species = deparse(substitute(.x))), 
          .id = "species")

```


And save this for use later

```{r save global model.sel data}

write_csv(global_model.sel_data,
          'data/processed/OSM_glm_global_model_sel_data.csv')
```


# Analysis Prep

## Summary

While the global models are interesting and yield relevant results there is an issue of addressing autocorrelation with such large models that we don't have the capacity to address at each spatial scale while still keeping the models the same so the only thing being compared is the buffer size. 

It's also relevant to wonder if these results would be different depending on if we look at exclusively anthropogenic or landscape features in a model and by reducing the variables in each model we can address this issue of autocorrelation much easier. So the next analysis will repeat what we've done above for each species but instead of using one global model for everything we will divide the data into disturbance and landscape covariates and run two separate models per species and see if the results differ. 

## Data prep

First let's subset the data into the two new groups we will use for this analysis so we can check for auto correlations within the data sets

### Anthropogenic

First let's generate the developed data set which includes only the covariates for the human factors indices
```{r subset developed data}

osm_anthro_df_2021_2022 <- osm_final_df_2021_2022 %>% 
  
  # use purr to apply following data manipulation steps to all the buffer data frames
  purrr::map(
    
    ~.x %>% 
      
      # de-select columns for landscape data (e.g. those that have the prefix 'lc_')
      select(!starts_with('lc_'))
  )
```



Now let's explore the correlations between variables at each buffer scale and see what features we may need to remove or group together (if appropriate)

### Correlation plots

Now we need to make correlation plots for each buffer width to see what variables are correlated at a given spatial scale. We can use `purrr::map()` with the `chart.Correlation()` function from the *PerformanceAnalytics* package to make correlation plots with a specified method (e.g., pearson, spearman, etc.) That also show histograms and scatterplots of each variable.


Let's do this for the anthropogenic data first

```{r correlation plots anthropogenic pearson, warning=FALSE}

osm_anthro_df_2021_2022 %>% 
  
  purrr::map(
    ~.x %>% 
      
      # select only columns with covaraites not other info
      select(harvest:osm_industrial) %>% 
      
      # use chart.correlation 
      chart.Correlation(.,
                        histogram = TRUE, 
                        method = "pearson")
  )
```
This creates a lot of plots (1 for each buffer size) and I haven't found a way to label them by the buffer size yet unfortunately. But hopefully there will be trends among the buffer sizes to simplify the process of choosing covariates

> in Rstudio you can click on the white square icon in the upper right-hand corner of the figures to open a new window with the plots so you can see the values easier

In order of buffer size I'm going to summarize covariates that are correlated below with their respective r2 values. I'm only listing correlations above 0.6 for each buffer size

* 250m
roads + veg edges 0.71
*this is to be expected as veg edges occur along the sides of roads (primarily) as well as other disturbance features. We will choose roads in the analysis over veg edges*       

* 500m
pipeline + transmission lines   0.63    
*we may be able to combine these*
roads + veg edges 0.73

* 750m    
pipeline + transmission lines 0.70    
roads + veg edges 0.74    

* 1000m   
pipeline + transmission lines 0.73    
roads + veg edges 0.79    

* 1250m   
pipeline + transmission lines 0.72    
roads + veg edges 0.81    

* 1500m   
pipeline + transmission lines 0.72    
roads + veg edges 0.84    
roads + wells 0.64    

* 1750m
pipeline + transmission lines 0.72    
roads + veg edges 0.85    
roads + wells 0.70    

* 2000m   
pipeline + transmission lines 0.72    
roads + veg edges 0.86    
roads + wells 0.73    

* 2250m   
pipeline + transmission lines 0.71    
roads + veg edges 0.87    
roads + wells 0.76    

* 2500m   
pipleine + roads 0.61   
pipeline + transmission lines 0.70    
roads + veg edges 0.88    
roads + wells 0.76    
roads + osm_industrial 0.61   

* 2750m   
pipeline + roads 0.61   
pipeline + transmission lines 0.70    
roads + veg edges 0.88    
roads + wells 0.76    
roads + osm_industrial 0.61   

* 3000m   
pipeline + roads 0.63   
pipeline + transmission lines 0.69    
roads + veg edges 0.88    
roads + wells 0.77    
roads + osm_industrial 0.63   

> at this point there are some obvious trends between roads and several features and pipelines and transmission lines. for simplicity sake I am only going to report correlations for variables not correlated with roads, as we will have to drop this covariate, and new pairs of highly correlated variables. I will also not specify the buffer size if it's found in more than one buffer 

* 3250m +   
veg edges + wells 0.61    
pipeline + wells 0.67    
pipeline + wells 0.69   

> In summary we should merge pipelines and transmission lines, remove roads, and remove veg edges from the analysis to insure we don't majorly violate assumptions of independence for our models. We will re-assess correlations after making these changes.


List of final variables   
*I first pasted the full list here and then deleted or added combined variables as I went through each buffer's correlation plot*

harvest   
seismic lines   
seismic lines 3D    
trails    
pipeline and transmission lines    
wells   
osm_industrial 


#### Reformat data

We'll reformat the anthropogenicsubset data here and re-run the correlation plots

```{r reformat anthro subset data}

osm_anthro_df_2021_2022 <- osm_anthro_df_2021_2022 %>% 
  
  # use purrr 
  purrr::map(
    
    ~.x %>% 
      
      # mutate data to combine pipeline and transmission line
      mutate(pipeline_transmission_lines = (pipeline + transmission_lines)) %>% 
      
      # remove correlated variables we won't include in subset models
      select(! c(pipeline, roads, veg_edges, transmission_lines)) %>% 
      
      # relocate column so new covariate is with others
      relocate(pipeline_transmission_lines,
               .after = wells)
  )
```

#### Re-run correlation plots

Now we should double check that this solves any issues of highly correlated variables by re-running the plots from before

```{r re-run corr plots anthro data, warning=FALSE}

osm_anthro_df_2021_2022 %>% 
  
  purrr::map(
    ~.x %>% 
      
      # select only columns with covariates not other info
      select(harvest:osm_industrial) %>% 
      
      # use chart.correlation 
      chart.Correlation(.,
                        histogram = TRUE, 
                        method = "pearson")
  )
```

Wells and the new pipelines and transmission lines variable seem to become increasingly correlated as the buffer size increases but the max r squared value is 0.66 so we will leave it in for now and discuss with others about whether or not to remove it since it's on the cusp.


### Landscape

Now let's do the same for the landscape data

```{r subset landscape data}

osm_landscape_df_2021_2022 <- osm_final_df_2021_2022 %>% 
  
   # use purr to apply following data manipulation steps to all the buffer data frames
  purrr::map(
    
    ~.x %>% 
      
      # de-select columns for developed data 
      select(!harvest:wells &
               !osm_industrial)
  )
```

Now we will follow the same process with the landscape data for generating correlation plots and assessing whaich variables need to be removed or combined

#### Correlation plots

```{r correlation plot landscape data, warning=FALSE}

osm_landscape_df_2021_2022 %>% 
  
  purrr::map(
    ~.x %>% 
      
       # select only columns with covariates not other info
      select(lc_grassland:lc_shrub) %>% 
      
      # use chart.correlation 
      chart.Correlation(.,
                        histogram = TRUE, 
                        method = "pearson")
  )
```

Below is a summary of the different buffer sizes and correlated variables

* 250m    
None >0.6   

* 500m
coniferous + broadleaf 0.63   

* 750m    
coniferous + broadleaf 0.66   

* 1000m   
coniferous + braodleaf 0.68   

> Coniferous and broadleaf appear to be the only variables highly correlated so I think what we will do is combine all 3 forest types into one category, because we really aren't interested in interpreting these individual variables but rather seeing if there are differences in which buffer is the best fit between development and landscape features. 

#### Reformat data

```{r reformat landscape data}

osm_landscape_df_2021_2022 <- osm_landscape_df_2021_2022 %>% 
  
  # use purrr to apply the functions to all data frames
  purrr::map(
    
    ~.x %>% 
      
      # use mutate to combine forest types into one variable
      mutate(lc_forest = lc_coniferous + lc_broadleaf + lc_mixed) %>% 
      
      # remove old variables
      select(! c(lc_coniferous, lc_broadleaf, lc_mixed)) %>% 
      
      # relocate the new column with. the other covariates
      relocate(lc_forest, 
               .after = buff_dist)
  )
```

Looks good! Now let's re-run the correlation plots 

#### Re-run correlation plots

```{r rerun correlation plot landscape data, warning=FALSE}

osm_landscape_df_2021_2022 %>% 
  
  purrr::map(
    ~.x %>% 
      
       # select only columns with covariates not other info
      select(lc_forest:lc_shrub) %>% 
      
      # use chart.correlation 
      chart.Correlation(.,
                        histogram = TRUE, 
                        method = "pearson")
  )
```

Well crap. Turns out the primary landscape types are forest and shrub so when we combine all three forest types we now have an issue with autocorrelation with the shrub landcover type. Might need to rethink the approach here. 

For now will use one or the other


# Subset Analysis

Now that the two separate data files are ready we can run an analysis with each, similar to what we did with the global models and see if this changes our findings from the global model or if there are differences in results between the two model subsets

## Anthropogenic

We will do another analysis for each species as we did previously.

### Black bear

```{r bear anthro models}

bear_anthro_mods <- osm_anthro_df_2021_2022 %>% 

  # use purrr map to run the same functions for all buffer sizes ((all objects in list))
  purrr::map(
    ~.x %>%

      # glmmTMB function let's us run the proportional binomial model using cbind to combine the present and absent columns for each species
     glmmTMB::glmmTMB(cbind(black_bear, absent_black_bear) ~
                        
                        # HFI that aren't correlated
                        scale(harvest) +
                        scale(seismic_lines) +
                        scale(seismic_lines_3D) +
                        scale(trails) +
                        scale(wells) +
                        scale(osm_industrial) +
                        scale(pipeline_transmission_lines) +
                        
                        # Random effect of array
                        (1|array),
                   data = .,
                   family = 'binomial'))

# run model selection and save the results as a tibble for graphing use later
bear_anthro_model.sel <- model.sel(bear_anthro_mods) %>% 
  
  as.data.frame() %>% 
  
  rownames_to_column(var = 'Model')  %>%
  
  mutate(Dataset = deparse(substitute(osm_anthro_df_2021_2022)))

# look at model selection results
bear_anthro_model.sel
```


We will use the `model.sel()` function from the *MuMIn* package to compare the global models for each buffer width and see which buffer fits the black bear data best

```{r bear anthro mod selection}

model.sel(bear_anthro_mods)

```
> This is quite a bit different from the global results which indicated that the 250m buffer was best fit for black bears, whereas this one it is the 4000m buffer

#### Top model summary

```{r bear dev mod summary}

summary(bear_anthro_mods$`4000 meter buffer`)
```

#### Quck test on scaling 

Going to run the models again WITHOUT scaling variables as recent literature suggests this may influence model results. 

```{r test bear dev mod}

test_bear_anthro_mods <- osm_anthro_df_2021_2022 %>% 

  # use purrr map to run the same functions for all buffer sizes ((all objects in list))
  purrr::map(
    ~.x %>%

      # glmmTMB function let's us run the proportional binomial model using cbind to combine the present and absent columns for each species
     glmmTMB::glmmTMB(cbind(black_bear, absent_black_bear) ~
                        
                        # HFI that aren't correlated
                        harvest +
                        seismic_lines +
                        seismic_lines_3D +
                        trails +
                        wells +
                        osm_industrial +
                        pipeline_transmission_lines +
                        
                        # Random effect of array
                        (1|array),
                   data = .,
                   family = 'binomial'))


model.sel(test_bear_anthro_mods)


```
> Interesting, you get almost the same results  but the 4000m buffer is the worst fit. There was a warning about model convergence issues which I suspect is the problem, this is fairly common with unscaled data. We will proceed with scaling the data as is standard practice still, but consider in discussion on ms how this may affect results. 


### Caribou 

```{r caribou anthro models}

caribou_anthro_mods <- osm_anthro_df_2021_2022 %>% 

  # use purrr map to run the same functions for all buffer sizes ((all objects in list))
  purrr::map(
    ~.x %>%

      # glmmTMB function let's us run the proportional binomial model using cbind to combine the present and absent columns for each species
     glmmTMB::glmmTMB(cbind(caribou, absent_caribou) ~
                        
                        # HFI that aren't correlated
                        scale(harvest) +
                        scale(seismic_lines) +
                        scale(seismic_lines_3D) +
                        scale(trails) +
                        scale(wells) +
                        scale(osm_industrial) +
                        scale(pipeline_transmission_lines) +
                        
                        # Random effect of array
                        (1|array),
                   data = .,
                   family = 'binomial'))

# run model selection and save the results as a tibble for graphing use later
caribou_anthro_model.sel <- model.sel(caribou_anthro_mods) %>% 
  
  as.data.frame() %>% 
  
  rownames_to_column(var = 'Model')  %>%
  
  mutate(Dataset = deparse(substitute(osm_anthro_df_2021_2022)))

# look at model selection results
caribou_anthro_model.sel

```
Let's look at the summary for the top model

```{r caribou anthro model summary}

summary(caribou_anthro_mods$`1000 meter buffer`)
```

### Coyote

```{r coyote anthro models}

coyote_anthro_mods <- osm_anthro_df_2021_2022 %>% 

  # use purrr map to run the same functions for all buffer sizes ((all objects in list))
  purrr::map(
    ~.x %>%

      # glmmTMB function let's us run the proportional binomial model using cbind to combine the present and absent columns for each species
     glmmTMB::glmmTMB(cbind(coyote, absent_coyote) ~
                        
                        # HFI that aren't correlated
                        scale(harvest) +
                        scale(seismic_lines) +
                        scale(seismic_lines_3D) +
                        scale(trails) +
                        scale(wells) +
                        scale(osm_industrial) +
                        scale(pipeline_transmission_lines) +
                        
                        # Random effect of array
                        (1|array),
                   data = .,
                   family = 'binomial'))

# run model selection and save the results as a tibble for graphing use later
coyote_anthro_model.sel <- model.sel(coyote_anthro_mods) %>% 
  
  as.data.frame() %>% 
  
  rownames_to_column(var = 'Model')  %>%
  
  mutate(Dataset = deparse(substitute(osm_anthro_df_2021_2022)))

# look at model selection results
coyote_anthro_model.sel

```
```{r coyote anthro model summary}

summary(coyote_anthro_mods$`4750 meter buffer`)
```

### Fisher

```{r fisher anthro models}

fisher_anthro_mods <- osm_anthro_df_2021_2022 %>% 

  # use purrr map to run the same functions for all buffer sizes ((all objects in list))
  purrr::map(
    ~.x %>%

      # glmmTMB function let's us run the proportional binomial model using cbind to combine the present and absent columns for each species
     glmmTMB::glmmTMB(cbind(fisher, absent_fisher) ~
                        
                        # HFI that aren't correlated
                        scale(harvest) +
                        scale(seismic_lines) +
                        scale(seismic_lines_3D) +
                        scale(trails) +
                        scale(wells) +
                        scale(osm_industrial) +
                        scale(pipeline_transmission_lines) +
                        
                        # Random effect of array
                        (1|array),
                   data = .,
                   family = 'binomial'))

# run model selection and save the results as a tibble for graphing use later
fisher_anthro_model.sel <- model.sel(fisher_anthro_mods) %>% 
  
  as.data.frame() %>% 
  
  rownames_to_column(var = 'Model')  %>%
  
  mutate(Dataset = deparse(substitute(osm_anthro_df_2021_2022)))

# look at model selection results
fisher_anthro_model.sel

```

```{r fisher anthro model summary}

summary(fisher_anthro_mods$`250 meter buffer`)
```


### Grey wolf

```{r wolf anthro models}

wolf_anthro_mods <- osm_anthro_df_2021_2022 %>% 

  # use purrr map to run the same functions for all buffer sizes ((all objects in list))
  purrr::map(
    ~.x %>%

      # glmmTMB function let's us run the proportional binomial model using cbind to combine the present and absent columns for each species
     glmmTMB::glmmTMB(cbind(grey_wolf, absent_grey_wolf) ~
                        
                        # HFI that aren't correlated
                        scale(harvest) +
                        scale(seismic_lines) +
                        scale(seismic_lines_3D) +
                        scale(trails) +
                        scale(wells) +
                        scale(osm_industrial) +
                        scale(pipeline_transmission_lines) +
                        
                        # Random effect of array
                        (1|array),
                   data = .,
                   family = 'binomial'))

# run model selection and save the results as a tibble for graphing use later
wolf_anthro_model.sel <- model.sel(wolf_anthro_mods) %>% 
  
  as.data.frame() %>% 
  
  rownames_to_column(var = 'Model')  %>%
  
  mutate(Dataset = deparse(substitute(osm_anthro_df_2021_2022)))

# look at model selection results
wolf_anthro_model.sel

```
```{r wolf anthro model summary}

summary(wolf_anthro_mods$`2000 meter buffer`)
```


### Lynx

```{r lynx anthro models}

lynx_anthro_mods <- osm_anthro_df_2021_2022 %>% 

  # use purrr map to run the same functions for all buffer sizes ((all objects in list))
  purrr::map(
    ~.x %>%

      # glmmTMB function let's us run the proportional binomial model using cbind to combine the present and absent columns for each species
     glmmTMB::glmmTMB(cbind(lynx, absent_lynx) ~
                        
                        # HFI that aren't correlated
                        scale(harvest) +
                        scale(seismic_lines) +
                        scale(seismic_lines_3D) +
                        scale(trails) +
                        scale(wells) +
                        scale(osm_industrial) +
                        scale(pipeline_transmission_lines) +
                        
                        # Random effect of array
                        (1|array),
                   data = .,
                   family = 'binomial'))

# run model selection and save the results as a tibble for graphing use later
lynx_anthro_model.sel <- model.sel(lynx_anthro_mods) %>% 
  
  as.data.frame() %>% 
  
  rownames_to_column(var = 'Model')  %>%
  
  mutate(Dataset = deparse(substitute(osm_anthro_df_2021_2022)))

# look at model selection results
lynx_anthro_model.sel

```
```{r lynx anthro model summary}

summary(lynx_anthro_mods$`250 meter buffer`)
```

### Moose

```{r moose anthro models}

moose_anthro_mods <- osm_anthro_df_2021_2022 %>% 

  # use purrr map to run the same functions for all buffer sizes ((all objects in list))
  purrr::map(
    ~.x %>%

      # glmmTMB function let's us run the proportional binomial model using cbind to combine the present and absent columns for each species
     glmmTMB::glmmTMB(cbind(moose, absent_moose) ~
                        
                        # HFI that aren't correlated
                        scale(harvest) +
                        scale(seismic_lines) +
                        scale(seismic_lines_3D) +
                        scale(trails) +
                        scale(wells) +
                        scale(osm_industrial) +
                        scale(pipeline_transmission_lines) +
                        
                        # Random effect of array
                        (1|array),
                   data = .,
                   family = 'binomial'))

# run model selection and save the results as a tibble for graphing use later
moose_anthro_model.sel <- model.sel(moose_anthro_mods) %>% 
  
  as.data.frame() %>% 
  
  rownames_to_column(var = 'Model')  %>%
  
  mutate(Dataset = deparse(substitute(osm_anthro_df_2021_2022)))

# look at model selection results
moose_anthro_model.sel

```

```{r moose anthro model summary}

summary(moose_anthro_mods$`750 meter buffer`)
```


### Red fox

```{r fox anthro models}

fox_anthro_mods <- osm_anthro_df_2021_2022 %>% 

  # use purrr map to run the same functions for all buffer sizes ((all objects in list))
  purrr::map(
    ~.x %>%

      # glmmTMB function let's us run the proportional binomial model using cbind to combine the present and absent columns for each species
     glmmTMB::glmmTMB(cbind(red_fox, absent_red_fox) ~
                        
                        # HFI that aren't correlated
                        scale(harvest) +
                        scale(seismic_lines) +
                        scale(seismic_lines_3D) +
                        scale(trails) +
                        scale(wells) +
                        scale(osm_industrial) +
                        scale(pipeline_transmission_lines) +
                        
                        # Random effect of array
                        (1|array),
                   data = .,
                   family = 'binomial'))

# run model selection and save the results as a tibble for graphing use later
fox_anthro_model.sel <- model.sel(fox_anthro_mods) %>% 
  
  as.data.frame() %>% 
  
  rownames_to_column(var = 'Model')  %>%
  
  mutate(Dataset = deparse(substitute(osm_anthro_df_2021_2022)))

# look at model selection results
fox_anthro_model.sel

```

```{r fox anthro model summary}

summary(fox_anthro_mods$`1750 meter buffer`)
```


### White-tailed deer

```{r deer anthro models}

deer_anthro_mods <- osm_anthro_df_2021_2022 %>% 

  # use purrr map to run the same functions for all buffer sizes ((all objects in list))
  purrr::map(
    ~.x %>%

      # glmmTMB function let's us run the proportional binomial model using cbind to combine the present and absent columns for each species
     glmmTMB::glmmTMB(cbind(`white-tailed_deer`, `absent_white-tailed_deer`) ~
                        
                        # HFI that aren't correlated
                        scale(harvest) +
                        scale(seismic_lines) +
                        scale(seismic_lines_3D) +
                        scale(trails) +
                        scale(wells) +
                        scale(osm_industrial) +
                        scale(pipeline_transmission_lines) +
                        
                        # Random effect of array
                        (1|array),
                   data = .,
                   family = 'binomial'))

# run model selection and save the results as a tibble for graphing use later
deer_anthro_model.sel <- model.sel(deer_anthro_mods) %>% 
  
  as.data.frame() %>% 
  
  rownames_to_column(var = 'Model')  %>%
  
  mutate(Dataset = deparse(substitute(osm_anthro_df_2021_2022)))

# look at model selection results
deer_anthro_model.sel 

```

```{r deer anthr model summary}

summary(deer_anthro_mods$`1500 meter buffer`)
```

### Save model results

We also want to save the output from the model.sel funciton for each species as one csv file for use plotting later like we did with the global analysis

```{r anthro model.sel data}

# provide list of model.sel data frames from global analysis

anthro_model.sel_data <- list(
  bear = bear_anthro_model.sel,
  caribou = caribou_anthro_model.sel,
  coyote = coyote_anthro_model.sel,
  fisher = fisher_anthro_model.sel,
  wolf = wolf_anthro_model.sel,
  lynx = lynx_anthro_model.sel,
  moose = moose_anthro_model.sel,
  fox = fox_anthro_model.sel,
  deer = deer_anthro_model.sel
) %>% 
  
  # use purrr to combine data and extract species names to use as a column
  map_dfr(~.x %>% 
            
            mutate(species = deparse(substitute(.x))), 
          .id = "species")

```


And save this for use later

```{r save anthro model.sel data}

write_csv(anthro_model.sel_data,
          'data/processed/OSM_glm_anthro_model_sel_data.csv')

```



## Landscape

Now we will duplicate this analysis but for data that only includes landscape features.

> For now we have to select EITHER lc_forest or lc_shrub as they are highly correlated

### Black bear

```{r bear land models}

bear_land_mods <- osm_landscape_df_2021_2022 %>% 

  # use purrr map to run the same functions for all buffer sizes ((all objects in list))
  purrr::map(
    ~.x %>%

      # glmmTMB function let's us run the proportional binomial model using cbind to combine the present and absent columns for each species
     glmmTMB::glmmTMB(cbind(black_bear, absent_black_bear) ~
                        
                        # Landscape classes that aren't correlated
                        scale(lc_forest) +
                        scale(lc_grassland) +
                        scale(lc_developed) +
                        
                        # Random effect of array
                        (1|array),
                   data = .,
                   family = 'binomial'))

# run model selection and save the results as a tibble for graphing use later
bear_land_model.sel <- model.sel(bear_land_mods) %>% 
  
  as.data.frame() %>% 
  
  rownames_to_column(var = 'Model')  %>%
  
  mutate(Dataset = deparse(substitute(osm_anthro_df_2021_2022)))

# look at model selection results
bear_land_model.sel 


```

```{r bear land mod summary}

summary(bear_land_mods$`250 meter buffer`)
```

### Caribou

```{r caribou land models}

caribou_land_mods <- osm_landscape_df_2021_2022 %>% 

  # use purrr map to run the same functions for all buffer sizes ((all objects in list))
  purrr::map(
    ~.x %>%

      # glmmTMB function let's us run the proportional binomial model using cbind to combine the present and absent columns for each species
     glmmTMB::glmmTMB(cbind(caribou, absent_caribou) ~
                        
                        # Landscape classes that aren't correlated
                        scale(lc_forest) +
                        scale(lc_grassland) +
                        scale(lc_developed) +
                        
                        # Random effect of array
                        (1|array),
                   data = .,
                   family = 'binomial'))

# run model selection and save the results as a tibble for graphing use later
caribou_land_model.sel <- model.sel(caribou_land_mods) %>% 
  
  as.data.frame() %>% 
  
  rownames_to_column(var = 'Model')  %>%
  
  mutate(Dataset = deparse(substitute(osm_anthro_df_2021_2022)))

# look at model selection results
caribou_land_model.sel 


```

```{r caribou land model summary}

summary(caribou_land_mods$`250 meter buffer`)
```


### Coyote

```{r coyote land models}
coyote_land_mods <- osm_landscape_df_2021_2022 %>% 

  # use purrr map to run the same functions for all buffer sizes ((all objects in list))
  purrr::map(
    ~.x %>%

      # glmmTMB function let's us run the proportional binomial model using cbind to combine the present and absent columns for each species
     glmmTMB::glmmTMB(cbind(coyote, absent_coyote) ~
                        
                        # Landscape classes that aren't correlated
                        scale(lc_forest) +
                        scale(lc_grassland) +
                        scale(lc_developed) +
                        
                        # Random effect of array
                        (1|array),
                   data = .,
                   family = 'binomial'))

# run model selection and save the results as a tibble for graphing use later
coyote_land_model.sel <- model.sel(coyote_land_mods) %>% 
  
  as.data.frame() %>% 
  
  rownames_to_column(var = 'Model')  %>%
  
  mutate(Dataset = deparse(substitute(osm_anthro_df_2021_2022)))

# look at model selection results
coyote_land_model.sel 


```

```{r coyote land mod summary}

summary(coyote_land_mods$`3750 meter buffer`)
```


### Fisher

```{r fisher land models}

fisher_land_mods <- osm_landscape_df_2021_2022 %>% 

  # use purrr map to run the same functions for all buffer sizes ((all objects in list))
  purrr::map(
    ~.x %>%

      # glmmTMB function let's us run the proportional binomial model using cbind to combine the present and absent columns for each species
     glmmTMB::glmmTMB(cbind(fisher, absent_fisher) ~
                        
                        # Landscape classes that aren't correlated
                        scale(lc_forest) +
                        scale(lc_grassland) +
                        scale(lc_developed) +
                        
                        # Random effect of array
                        (1|array),
                   data = .,
                   family = 'binomial'))

# run model selection and save the results as a tibble for graphing use later
fisher_land_model.sel <- model.sel(fisher_land_mods) %>% 
  
  as.data.frame() %>% 
  
  rownames_to_column(var = 'Model')  %>%
  
  mutate(Dataset = deparse(substitute(osm_anthro_df_2021_2022)))

# look at model selection results
fisher_land_model.sel 


```

```{r fisher land mod summary}

summary(fisher_land_mods$`2500 meter buffer`)
```


### Grey wolf

```{r wolf land models}

wolf_land_mods <- osm_landscape_df_2021_2022 %>% 

  # use purrr map to run the same functions for all buffer sizes ((all objects in list))
  purrr::map(
    ~.x %>%

      # glmmTMB function let's us run the proportional binomial model using cbind to combine the present and absent columns for each species
     glmmTMB::glmmTMB(cbind(grey_wolf, absent_grey_wolf) ~
                        
                        # Landscape classes that aren't correlated
                        scale(lc_forest) +
                        scale(lc_grassland) +
                        scale(lc_developed) +
                        
                        # Random effect of array
                        (1|array),
                   data = .,
                   family = 'binomial'))

# run model selection and save the results as a tibble for graphing use later
wolf_land_model.sel <- model.sel(wolf_land_mods) %>% 
  
  as.data.frame() %>% 
  
  rownames_to_column(var = 'Model')  %>%
  
  mutate(Dataset = deparse(substitute(osm_anthro_df_2021_2022)))

# look at model selection results
wolf_land_model.sel 


```

```{r wolf land mod summary}

summary(wolf_land_mods$`3500 meter buffer`)
```


### Lynx

```{r lynx land models}

lynx_land_mods <- osm_landscape_df_2021_2022 %>% 

  # use purrr map to run the same functions for all buffer sizes ((all objects in list))
  purrr::map(
    ~.x %>%

      # glmmTMB function let's us run the proportional binomial model using cbind to combine the present and absent columns for each species
     glmmTMB::glmmTMB(cbind(lynx, absent_lynx) ~
                        
                        # Landscape classes that aren't correlated
                        scale(lc_forest) +
                        scale(lc_grassland) +
                        scale(lc_developed) +
                        
                        # Random effect of array
                        (1|array),
                   data = .,
                   family = 'binomial'))

# run model selection and save the results as a tibble for graphing use later
lynx_land_model.sel <- model.sel(lynx_land_mods) %>% 
  
  as.data.frame() %>% 
  
  rownames_to_column(var = 'Model')  %>%
  
  mutate(Dataset = deparse(substitute(osm_anthro_df_2021_2022)))

# look at model selection results
lynx_land_model.sel 


```

```{r lynx land mod summary}

summary(lynx_land_mods$`500 meter buffer`)
```


### Moose

```{r moose land models}

moose_land_mods <- osm_landscape_df_2021_2022 %>% 

  # use purrr map to run the same functions for all buffer sizes ((all objects in list))
  purrr::map(
    ~.x %>%

      # glmmTMB function let's us run the proportional binomial model using cbind to combine the present and absent columns for each species
     glmmTMB::glmmTMB(cbind(moose, absent_moose) ~
                        
                        # Landscape classes that aren't correlated
                        scale(lc_forest) +
                        scale(lc_grassland) +
                        scale(lc_developed) +
                        
                        # Random effect of array
                        (1|array),
                   data = .,
                   family = 'binomial'))

# run model selection and save the results as a tibble for graphing use later
moose_land_model.sel <- model.sel(moose_land_mods) %>% 
  
  as.data.frame() %>% 
  
  rownames_to_column(var = 'Model')  %>%
  
  mutate(Dataset = deparse(substitute(osm_anthro_df_2021_2022)))

# look at model selection results
moose_land_model.sel 


```

```{r moose land mod summary}

summary(moose_land_mods$`250 meter buffer`)
```


### Red fox

```{r fox land models}

fox_land_mods <- osm_landscape_df_2021_2022 %>% 

  # use purrr map to run the same functions for all buffer sizes ((all objects in list))
  purrr::map(
    ~.x %>%

      # glmmTMB function let's us run the proportional binomial model using cbind to combine the present and absent columns for each species
     glmmTMB::glmmTMB(cbind(red_fox, absent_red_fox) ~
                        
                        # Landscape classes that aren't correlated
                        scale(lc_forest) +
                        scale(lc_grassland) +
                        scale(lc_developed) +
                        
                        # Random effect of array
                        (1|array),
                   data = .,
                   family = 'binomial'))

# run model selection and save the results as a tibble for graphing use later
fox_land_model.sel <- model.sel(fox_land_mods) %>% 
  
  as.data.frame() %>% 
  
  rownames_to_column(var = 'Model')  %>%
  
  mutate(Dataset = deparse(substitute(osm_anthro_df_2021_2022)))

# look at model selection results
fox_land_model.sel 


```

```{r fox land mod summary}

summary(fox_land_mods$`4750 meter buffer`)
```


### White-tailed deer

```{r deer land models}

deer_land_mods <- osm_landscape_df_2021_2022 %>% 

  # use purrr map to run the same functions for all buffer sizes ((all objects in list))
  purrr::map(
    ~.x %>%

      # glmmTMB function let's us run the proportional binomial model using cbind to combine the present and absent columns for each species
     glmmTMB::glmmTMB(cbind(`white-tailed_deer`, `absent_white-tailed_deer`) ~
                        
                        # Landscape classes that aren't correlated
                        scale(lc_forest) +
                        scale(lc_grassland) +
                        scale(lc_developed) +
                        
                        # Random effect of array
                        (1|array),
                   data = .,
                   family = 'binomial'))

# run model selection and save the results as a tibble for graphing use later
deer_land_model.sel <- model.sel(deer_land_mods) %>% 
  
  as.data.frame() %>% 
  
  rownames_to_column(var = 'Model')  %>%
  
  mutate(Dataset = deparse(substitute(osm_anthro_df_2021_2022)))

# look at model selection results
deer_land_model.sel 


```

### Save model results

We also want to save the output from the model.sel funciton for each species as one csv file for use plotting later like we did with the previous analyses

```{r land model.sel data}

# provide list of model.sel data frames from global analysis

land_model.sel_data <- list(
  bear = bear_land_model.sel,
  caribou = caribou_land_model.sel,
  coyote = coyote_land_model.sel,
  fisher = fisher_land_model.sel,
  wolf = wolf_land_model.sel,
  lynx = lynx_land_model.sel,
  moose = moose_land_model.sel,
  fox = fox_land_model.sel,
  deer = deer_land_model.sel
) %>% 
  
  # use purrr to combine data and extract species names to use as a column
  map_dfr(~.x %>% 
            
            mutate(species = deparse(substitute(.x))), 
          .id = "species")

```


And save this for use later

```{r save land model.sel data}

write_csv(land_model.sel_data,
          'data/processed/OSM_glm_land_model_sel_data.csv')

```


> In summary it does matter whether you are looking at landscape or anthropogenic features which spatial scale you use. Only two species (lynx and moose) had spatial scales for both top models within 1000m (1km). There were also more well-defined top models (delta AIC greater than 2.00) when you subset data to specifically look at anthro or landscape features. 


