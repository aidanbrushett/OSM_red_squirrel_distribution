---
title: "Import and explore covariates"
author: "Aidan Brushett"
date: "`r Sys.Date()`"
output: 
  html_document:
    theme: default
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 0. Before you begin

Aidan Brushett
M.Sc. Student
University of Victoria    
School of Environmental Studies     
Email: [aidanbrushett@uvic.ca](aidanbrushett@uvic.ca)

Emerald Arthurs
M.Sc. Student
University of Victoria    
School of Environmental Studies     
Email: [XXXX@uvic.ca](XXXX@uvic.ca)
***

# 1. Setup

```{r}
rm(list=ls()) # start fresh :)

library(tidyverse)
library(ggplot2)
library(writexl)

# These are functions that can sometimes get masked by other packages. Shouldn't be an issue and could be removed.
select <- dplyr::select
filter <- dplyr::filter
mutate <- dplyr::mutate
summarize <- dplyr::summarize
# Cheeky function that means "not in"
`%nin%` = Negate(`%in%`)
```

# 2. Import and merge response variable and covariates

```{r}
covariates <- read_csv("./data/processed/OSM_all_covariates_2021_2022_2023.csv")

response <- read_csv("./data/processed/OSM_proportional_weekly_presence_2021_2022_2023.csv")

setdiff(covariates$site, response$site)
setdiff(response$site, covariates$site)

data_raw <- left_join(response, covariates, by = c("site", "array")) %>%
  
  relocate(array, site, buffer_dist, lat, long, easting_12n, northing_12n) %>%
  
  mutate(seismic = seismic_lines + seismic_lines_3D,
         pipe_trans = transmission_lines + pipeline) %>%
  
  select(-pipeline, -transmission_lines, -seismic_lines, -seismic_lines_3D)
```

# 3. Exploratory analysis

Do we have a lot of variation in the data for our covariates? Let's take a look at the 500, 1000, 2500, and 5000 m scale. We have a fuckload of configuration metrics and it would be stupid to explore all of them. For now let's take a look at a few key ones we think might be interesting or useful for our models.

Let's extract:

- `np` number of patches per landcover type
- `pd` patch density per 100 Ha per landcover type
- `area_mn` mean patch area mean area of all patches of a landcover type - many small or few large?
- `lpi` largest patch index - percent of landscape covered by largest patch, a measure of relative dominance
- `tca` total core area per landcover type
- `core_mn` mean core area per patch per landcover type
- `ed` edge density (edge length in meters per landcover type)
- `cohesion` connectedness of patches
- `split` splitting index describing patch size distribution/fragmentation. We will NOT use this since it looks like it did not extract properly. 

For a few specific feature types of interest:

- `anthropogenic` aggregate class of entire human footprint 
- `natural` aggregate class of all non-water landcover
- `conifer_forest`
- `broadleaf_forest`
- `mixed_forest`
- `seismic` not tca, core_mn, cohesion, split
- `pipe_trans` not tca, core_mn, cohesion, split
- `harvest` not tca, core_mn, cohesion, split
- `wells` not tca, core_mn, cohesion, split
- `roads` not tca, core_mn, cohesion, split
- `osm_industrial` not tca, core_mn, cohesion, split

```{r}
# Some metrics we want for basically all of the feature types
#feature_config <- c("anthropogenic", "natural", "coniferous_forest", "broadleaf_forest", 
#                    "mixed_forest", "grassland", "shrubland", "seismic_lines", 
#                    "seismic_lines_3d", "pipeline", "transmission_lines", "wells", 
#                    "harvest", "roads", "osm_industrial")
#metric_config <- c("np", "pd", "area_mn", "lpi", "ed")

#config <- crossing(feature = feature_config, metric = metric_config) %>%
#  mutate(name = str_c(feature, metric, sep = "_")) %>%
#  pull(name)

# Some metrics we want for a subset of the feature types
#feature_config_partial <- c("anthropogenic", "natural", "coniferous_forest", "broadleaf_forest", 
#                           "mixed_forest", "grassland", "shrubland")
#metric_config_partial <- c("tca", "core_mn", "cohesion")

# Collect them all into one list that we can input to 'select'
#config_vars <- c(config, config_partial)

# Some metrics we want for a subset of the feature types
config_vars <- crossing(feature = c("anthropogenic", "natural"), 
                        metric = c("tca", "ed", "cohesion")) %>%
  
  mutate(name = str_c(feature, metric, sep = "_")) %>%
  
  pull(name)

data <- data_raw %>%
  
  select(1:48, config_vars)
```

Let's look at how much variation we have in our metrics from histograms. For now we'll loop through data that is pooled across all 20 buffer sizes. This is a coarse, for-interest-only tool that we can look at when building the candidate model set. 

```{r}
data %>% 
  
  select(36:ncol(.)) %>%
  
  # use imap which will retain both the data (x) and the variable names (y)
  imap(~ ggplot(mapping = aes(x = .x)) +
         geom_histogram(bins = 60, fill = "black", color = "black") +
         labs(title = .y, x = .y, y = "Count") +
         theme_classic())
```

Now let's look at correlation among variables. We have a fuck ton of variables to look at so for now we'll export to excel. 

```{r}
buffers <- seq(250, 5000, by = 250)

corr_data <- purrr::map(buffers, 
                        ~ data %>% 
                          
                          filter(buffer_dist == .x) %>%
                          
                          select(36:ncol(.)) %>%
                          
                          # pairwise complete observations right now since I'm not sure how to manage all the NAs in the configuration metrics yet
                          corrr::correlate(., use = "pairwise.complete.obs", 
                                           method = "pearson", 
                                           diagonal = NA, 
                                           quiet = TRUE) %>%
                          
                          as_tibble() %>%
                          
                          mutate(across(everything(), ~ if_else(row_number() >= min(which(is.na(.))), NA, .))) %>%
                          
                          select(rev(names(.))) %>% 
                          
                          relocate(term)
                        
                        ) %>% 
  
  set_names(paste0(buffers, "m"))

writexl::write_xlsx(corr_data, "./data/processed/OSM_all_covariates_correlation.xlsx")
```

# 4. Summary table of covariates

```{r}
covariates <- data %>%
  
  select(36:ncol(.)) %>%
  
  summarise(across(everything(), list(min_value = min, max_value = max))) %>%
  pivot_longer(cols = everything(), names_to = c("covariate", ".value"), names_sep = "__")



  
  
  
```























