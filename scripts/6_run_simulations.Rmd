---
title: "Submodels and final models"
author: "Aidan Brushett and Emerald Arthurs"
date: "`r Sys.Date()`"
output: 
  html_document:
    theme: default
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      paged.print=TRUE,
                      eval= TRUE)
```

# Before you begin

This script is number 6 of 6 in a series of scripts used to replicate the analyses presented in the paper: "Life on the edge: Industrial footprint and edge effects variably affect the distribution of a boreal small mammal"

This script was used to fit models to simulated data and get a sense of the predictive accuracy of our red squirrel models. 

When running these scripts, please ensure that you have downloaded the [complete GitHub repository](www.github.com/aidanbrushett/OSM-red_squirrel-distribution). This will ensure you have all the files, data, and proper folder structure you will need to run this code and associated analyses. 

Also make sure you open RStudio through the R project (OSM_red_squirrel_distribution.Rproj). This will automatically set your working directory to the correct place (wherever you saved the repository) and ensure you don't have to change the file paths for some of the data. This analysis was initially run in R v4.3.0. If you have any questions or concerns, please contact one of the authors (in order):

Aidan Brushett
M.Sc. Student
University of Victoria    
School of Environmental Studies     
Email: [aidanbrushett@uvic.ca](aidanbrushett@uvic.ca)

Emerald Arthurs
M.Sc. Student
University of Victoria    
School of Environmental Studies     

***

# 0. Setup

```{r libraries, message=FALSE, warning=FALSE}
rm(list = ls())
#library(MASS)
library(glmmTMB)
#library(lme4)
library(tidyverse)
library(MuMIn)
#library(PerformanceAnalytics)
library(ggpubr)
```


# 1. Re-construct the final dataset (best spatial scales)

## 1.1. Reimport the data

```{r data for modelling}
covs <- read_csv("./data/processed/OSM_all_covariates_HFI_SBFI_final.csv")

response <- read_csv("./data/processed/OSM_monthly_detections_2021_2022_2023.csv") %>%
  
  # Only species we want is red squirrel
  filter(species == "red squirrel") %>%
  
  # Only want detections column
  select(-species, -presence) %>%
  
  rename(squirrel = detections)

# Add the covariates to the response variable 
data <- response %>%
  
  left_join(covs, by = c("array", "site"))

# Make sure there are 20 rows per site/month/year 
data %>% 
  
  group_by(site, month, year) %>%
  
  summarize(n_obs = n()) %>%
  
  arrange(n_obs)
# 20 for everything. Looks good!!

# z-scaling for variables WITHIN each buffer 
data_scaled <- data %>%
  
  group_by(buffer_dist) %>%
  
  mutate(across(cfi_site:last_col(), ~ as.numeric(scale(.)))) %>%
  
  ungroup(.)

# The mean will be 0 even though we grouped first, since the mean for each buffer is still 0. 
summary(data_scaled)

rm(covs, response)
```

## 1.2. Re-identify top scales:

```{r}
# Pull from the model or specify manually. Manual means we don't need to re-run this every time. 
nat_buffer <- 100

comp_buffer <- 4250

config_buffer <- 2250
```

## 1.3. Pull out the final data again

We will pull out the predictors from the submodels **at the appropriate spatial scales** and merge this into one big dataset for final models. This selects a couple extra columns that we don't actually want to model but that's fine, this was efficient. This is the *unscaled* data so that we can run the sampler and apply appropriate constraints before scaling the data again. 

```{r}
data_final <- bind_cols(
  
  # response variables
  data %>%
    select(1:squirrel) %>%
    distinct(),
  
  # natural data scaled by natural buffer
  data %>% 
    filter(buffer_dist == nat_buffer) %>%
    select(fire_0_15:lc_wetland_treed) %>%
    mutate(natural_buffer = nat_buffer), # won't use this column, just keeping track of the scale somehow
  
  # composition data scaled by composition buffer
  data %>% 
    filter(buffer_dist == comp_buffer) %>%
    select(harvest_0_15:wells_total) %>%
    mutate(comp_buffer = comp_buffer), # won't use this column, just keeping track of the scale somehow
  
  # configuration data
  data %>% 
    filter(buffer_dist == config_buffer) %>%
    select(contains("nonanthro") | contains("landscape") | contains("cfi")) %>%
    mutate(config_buffer = config_buffer) # won't use this column, just keeping track of the scale somehow
  ) %>%
  
  relocate(contains("buffer"), .after=("squirrel"))

summary(data_final)
```

## 1.4. Re-fit the top model:

Have to fit using the scaled data. Hacky way to deal with scaling and code is a bit repetitive but it works. 

```{r}
data_final_scaled <- bind_cols(
  
  # response variables
  data_scaled %>%
    select(1:squirrel) %>%
    distinct(),
  
  # natural data scaled by natural buffer
  data_scaled %>% 
    filter(buffer_dist == nat_buffer) %>%
    select(fire_0_15:lc_wetland_treed) %>%
    mutate(natural_buffer = nat_buffer), # won't use this column, just keeping track of the scale somehow
  
  # composition data scaled by composition buffer
  data_scaled %>% 
    filter(buffer_dist == comp_buffer) %>%
    select(harvest_0_15:wells_total) %>%
    mutate(comp_buffer = comp_buffer), # won't use this column, just keeping track of the scale somehow
  
  # configuration data
  data_scaled %>% 
    filter(buffer_dist == config_buffer) %>%
    select(contains("nonanthro") | contains("landscape") | contains("cfi")) %>%
    mutate(config_buffer = config_buffer) # won't use this column, just keeping track of the scale somehow
  ) %>%
  
  relocate(contains("buffer"), .after=("squirrel"))

  m_edgeXcfi <- glmmTMB(squirrel ~ 
                        
                        # natural covariates
                        fire_0_15 +
                        lc_broadleaf +
                        lc_coniferous +
                        lc_mixedwood + 
                      
                        # configuration variables
                        #landscape_shei +
                        nonanthro_ed + 
                        cfi_site +
                        nonanthro_ed*cfi_site +
                        #landscape_mesh +

                        (1|array/site),

                      data = data_final_scaled, 
                      family = nbinom2, 
                      na.action = na.fail)

summary(m_edgeXcfi)
```

# 2. Run the simulations

## 2.1. Simulation function

```{r}
simulate_top_model <- function(model, original_data, n_array, n_site_per_array, n_obs_per_site, sampler_type){
  
  # Fixed effects in order of model appearance
  B0 <- fixef(model)$cond[1]
  B1 <- fixef(model)$cond[2]
  B2 <- fixef(model)$cond[3]
  B3 <- fixef(model)$cond[4]
  B4 <- fixef(model)$cond[5]
  B5 <- fixef(model)$cond[6]
  B6 <- fixef(model)$cond[7]
  B7 <- fixef(model)$cond[8]
  
  # Random effects
  SD_site <- sqrt(as.numeric(summary(model)$varcor$cond[["site:array"]]))
  SD_array <- sqrt(as.numeric(summary(model)$varcor$cond[["array"]]))

  if(sampler_type == "normal"){
    # Generate data values based on normal distribution
    fire_0_15 <- rnorm(100000, mean = mean(original_data$fire_0_15), sd = sd(original_data$fire_0_15))
    lc_broadleaf <- rnorm(100000, mean = mean(original_data$lc_broadleaf), sd = sd(original_data$lc_broadleaf))
    lc_coniferous <- rnorm(100000, mean = mean(original_data$lc_coniferous), sd = sd(original_data$lc_coniferous))
    lc_mixedwood <- rnorm(100000, mean = mean(original_data$lc_mixedwood), sd = sd(original_data$lc_mixedwood))
    nonanthro_ed <- rnorm(100000, mean = mean(original_data$nonanthro_ed), sd = sd(original_data$nonanthro_ed))
    cfi_site <- rnorm(100000, mean = mean(original_data$cfi_site), sd = sd(original_data$cfi_site))
  }
  
  
  if(sampler_type == "uniform"){
    # Generate data values based on uniform distribution
    fire_0_15 <- runif(100000, min = min(original_data$fire_0_15), max = max(original_data$fire_0_15))
    lc_broadleaf <- runif(100000, min = min(original_data$lc_broadleaf), max = max(original_data$lc_broadleaf))
    lc_coniferous <- runif(100000, min = min(original_data$lc_coniferous), max = max(original_data$lc_coniferous))
    lc_mixedwood <- runif(100000, min = min(original_data$lc_mixedwood), max = max(original_data$lc_mixedwood))
    nonanthro_ed <- runif(100000, min = min(original_data$nonanthro_ed), max = max(original_data$nonanthro_ed))
    cfi_site <- runif(100000, min = min(original_data$cfi_site), max = max(original_data$cfi_site))
  }
  
  data_sim <- tibble(
                fire_0_15,
                lc_broadleaf,
                lc_coniferous,
                lc_mixedwood,
                nonanthro_ed,
                cfi_site
                ) %>%
    
    mutate(landcover = lc_broadleaf + lc_coniferous + lc_mixedwood) %>%
  
    filter(if_all(everything(), ~ . >= 0),
           landcover<1) %>%
    
    filter(row_number(.) <= n_array * n_site_per_array) %>%
    
    # Scale the data using the original scaled values
    mutate(
      fire_0_15 = (fire_0_15 - mean(original_data$fire_0_15, na.rm = TRUE)) / sd(original_data$fire_0_15, na.rm = TRUE),
      lc_broadleaf = (lc_broadleaf - mean(original_data$lc_broadleaf, na.rm = TRUE)) / sd(original_data$lc_broadleaf, na.rm = TRUE),
      lc_coniferous = (lc_coniferous - mean(original_data$lc_coniferous, na.rm = TRUE)) / sd(original_data$lc_coniferous, na.rm = TRUE),
      lc_mixedwood = (lc_mixedwood - mean(original_data$lc_mixedwood, na.rm = TRUE)) / sd(original_data$lc_mixedwood, na.rm = TRUE),
      nonanthro_ed = (nonanthro_ed - mean(original_data$nonanthro_ed, na.rm = TRUE)) / sd(original_data$nonanthro_ed, na.rm = TRUE),
      cfi_site = (cfi_site - mean(original_data$cfi_site, na.rm = TRUE)) / sd(original_data$cfi_site, na.rm = TRUE)
    ) %>%
    
    mutate(array = paste0("Array", rep(1:n_array, each = n_site_per_array)),
           site = paste0(array, "_", 1:n_site_per_array)) %>%
  
    crossing(obs = 1:n_obs_per_site, .) %>%
      
    group_by(array) %>% 
    
    mutate(ranef_array = rnorm(n = 1, mean = 0, sd = SD_array)) %>%
    
    ungroup() %>%
    
    group_by(array, site) %>%
    
    mutate(ranef_site = rnorm(n = 1, mean = 0, sd = SD_site)) %>%
    
    ungroup() %>%
    
    mutate(eta = B0 + 
               B1 * fire_0_15 + 
               B2 * lc_broadleaf +
               B3 * lc_coniferous + 
               B4 * lc_mixedwood +
               B5 * nonanthro_ed + 
               B6 * cfi_site +
               B7 * nonanthro_ed * cfi_site + 
               ranef_array + 
               ranef_site,
             
             mu = exp(eta),
             
             squirrel = rnbinom(n = n(), mu = mu, size = sigma(model)))
  
  sim_naive_occ <- data_sim %>%
    group_by(site) %>%
    summarize(dets = max(squirrel)) %>%
    mutate(presence = ifelse(dets > 0, 1, 0)) %>%
    summarize(sum(presence)) %>%
    as.numeric()
  
  sim_indet <- sum(data_sim$squirrel)
  
  sim <- glmmTMB(squirrel ~ 
                            
                            # natural covariates
                            fire_0_15 +
                            lc_broadleaf +
                            lc_coniferous +
                            lc_mixedwood + 
                          
                            # configuration variables
                            #landscape_shei +
                            nonanthro_ed + 
                            cfi_site +
                            nonanthro_ed*cfi_site +
                            #landscape_mesh +
    
                            (1|array/site),
    
                          data = data_sim, 
                          family = nbinom2, 
                          na.action = na.fail)
    
  
  sim_summary <- tibble(cov = names(fixef(sim)$cond),
                value = fixef(sim)$cond) %>%
      
      pivot_wider(names_from = cov) %>%
      
      mutate(convergence = sim$fit$convergence,
             n_array = n_array,
             n_site_per_array = n_site_per_array,
             n_obs_per_site = n_obs_per_site,
             sim_indet = sim_indet,
             sim_naive_occ = sim_naive_occ,
             sampler_type = sampler_type,
             sim_date = as.character(Sys.Date()),
             )
  
  # Only return a model if it converged
  #if(sim$fit$convergence==0){
  #  return(sim_summary)
  #}
  
}

```

## 2.2. Run simulations

```{r, eval = FALSE}
# sim_master_results <- list()

# 1000 simulations with normal sampler
for(i in 1:100) {

cat("\r\r Working on `normal` batch", i)
  
load("./data/raw/simulation_checkpoint.RData")

sim_results <- purrr::map_dfr(1:10, ~
                 simulate_top_model(model = m_edgeXcfi, 
                                    original_data = data_final, 
                                    n_array = 10,
                                    n_site_per_array = 43,
                                    n_obs_per_site = 10,
                                    sampler_type = "normal"
                                    )
                 )

sim_master_results[[length(sim_master_results)+1]] <- sim_results

save(sim_master_results, file = "./data/raw/simulation_checkpoint.RData")
}

# 1000 simulations with uniform sampler
for(i in 1:100) {

cat("\r\r Working on `uniform` batch", i)
  
load("./data/raw/simulation_checkpoint.RData")

sim_results <- purrr::map_dfr(1:10, ~
                 simulate_top_model(model = m_edgeXcfi, 
                                    original_data = data_final, 
                                    n_array = 10,
                                    n_site_per_array = 43,
                                    n_obs_per_site = 10,
                                    sampler_type = "uniform"
                                    )
                 )

sim_master_results[[length(sim_master_results)+1]] <- sim_results

save(sim_master_results, file = "./data/raw/simulation_checkpoint.RData")
}

# 1000 simulations with reduced sites per array
for(i in 1:100) {

cat("\r\r Working on `reduced sites` batch", i)
  
load("./data/raw/simulation_checkpoint.RData")

sim_results <- purrr::map_dfr(1:10, ~
                 simulate_top_model(model = m_edgeXcfi, 
                                    original_data = data_final, 
                                    n_array = 10,
                                    n_site_per_array = 22,
                                    n_obs_per_site = 10,
                                    sampler_type = "uniform"
                                    )
                 )

sim_master_results[[length(sim_master_results)+1]] <- sim_results

save(sim_master_results, file = "./data/raw/simulation_checkpoint.RData")
}
```

# 3. Visualize results of the simulations

Let's take a look at the master results

```{r}
load("./data/raw/simulation_checkpoint.RData")

# Fetch the simulation results
sim_master_results_df <-  sim_master_results %>%
    bind_rows() %>%
    distinct() # Make sure there are no duplicate simulations. 
    
```

Let's also import the pretty names

```{r}
pretty_names <- read_csv("./tables/OSM_all_covariates_formatted_names.csv")
```


Plot using the normal (Gaussian) sampler

```{r}
true_vals <- enframe(fixef(m_edgeXcfi)$cond, name = "term", value = "value")

# Run simulations
sim_coefficient_plots <- purrr::map(true_vals$term, ~{
  
  # Pretty label for the plot
  label <- (pretty_names %>% filter(Covariate == .x))$PrettyName

  true_val <- (true_vals %>% filter(term==.x))$value

  # Fetch the simulation results
  sim_master_results_df %>%
    
    # For a specific subset of simulations
    filter(sampler_type == "normal",
           n_site_per_array == 43,
           convergence == 0) %>%
  
    # Pivot to long format to make our lives easier in purrr
    pivot_longer(., cols = 1:8) %>%
    
    # Coefficient values for just the variable we want
    filter(name == .x) %>%
    
    # Plot it
    ggplot(., aes(x = value)) + 
  
      geom_vline(xintercept = 0, color = "grey70") +  # Dotted vertical line at x = 0
  
      geom_density(fill = "darkred", alpha = 0.3) + 
    
      geom_vline(xintercept = true_val, 
                 linetype = "dashed", color = "darkred", linewidth=0.8) +  # Dotted vertical line at x = 0
  
        # Crop the axis since model weights are low
      scale_y_continuous(expand = expansion(mult = c(0, 0.05))) + 
    
      scale_x_continuous(limits = c(true_val-0.75, true_val+0.75), expand = c(0,0)) +
    
      labs(y = "", 
           x = "", 
           title = label) +
    
      theme_bw() + 
    
      theme(panel.grid = element_blank())  # Remove background panel grid
})

ggpubr::ggarrange(plotlist = sim_coefficient_plots, ncol = 3, nrow = 3) + 
  bgcolor("white")

ggsave("./figures/top_model_simulations_coefficient_density_gaussian_sampler.png", width = 9, height = 6)
```


Plot using the uniform distribution sampler

```{r}
pretty_names <- read_csv("./tables/OSM_all_covariates_formatted_names.csv")

true_vals <- enframe(fixef(m_edgeXcfi)$cond, name = "term", value = "value")

# Run simulations
sim_coefficient_plots <- purrr::map(true_vals$term, ~{
  
  # Pretty label for the plot
  label <- (pretty_names %>% filter(Covariate == .x))$PrettyName

  true_val <- (true_vals %>% filter(term==.x))$value
  
  # Fetch the simulation results
  sim_master_results_df %>%
    
    # For a specific subset of simulations
    filter(sampler_type == "uniform",
           n_site_per_array == 43,
           convergence == 0) %>%
  
    # Pivot to long format to make our lives easier in purrr
    pivot_longer(., cols = 1:8) %>%
    
    # Coefficient values for just the variable we want
    filter(name == .x) %>%
    
    # Plot it
    ggplot(., aes(x = value)) + 
  
      geom_vline(xintercept = 0, color = "grey70") +  # Dotted vertical line at x = 0
  
      geom_density(fill = "darkred", alpha = 0.3) + 
    
      geom_vline(xintercept = true_val, 
                 linetype = "dashed", color = "darkred", linewidth=0.8) +  # Dotted vertical line at x = 0
  
        # Crop the axis since model weights are low
      scale_y_continuous(expand = expansion(mult = c(0, 0.05))) + 
    
      scale_x_continuous(limits = c(true_val-0.5, true_val+0.5), expand = c(0,0)) +
    
      labs(y = "", 
           x = "", 
           title = label) +
    
      theme_bw() + 
    
      theme(panel.grid = element_blank())  # Remove background panel grid
})

ggpubr::ggarrange(plotlist = sim_coefficient_plots, ncol = 3, nrow = 3) + 
  bgcolor("white")

ggsave("./figures/top_model_simulations_coefficient_density_uniform_sampler.png", width = 9, height = 6)
```


Plot using the uniform sampler *and* reduced sample size

```{r}
pretty_names <- read_csv("./tables/OSM_all_covariates_formatted_names.csv")

true_vals <- enframe(fixef(m_edgeXcfi)$cond, name = "term", value = "value")

# Run simulations
sim_coefficient_plots <- purrr::map(true_vals$term, ~{
  
  # Pretty label for the plot
  label <- (pretty_names %>% filter(Covariate == .x))$PrettyName

  true_val <- (true_vals %>% filter(term==.x))$value
  
  # Fetch the simulation results
  sim_master_results_df %>%
    
    # For a specific subset of simulations
    filter(sampler_type == "uniform",
           n_site_per_array == 22,
           convergence == 0) %>%
  
    # Pivot to long format to make our lives easier in purrr
    pivot_longer(., cols = 1:8) %>%
    
    # Coefficient values for just the variable we want
    filter(name == .x) %>%
    
    # Plot it
    ggplot(., aes(x = value)) + 
  
      geom_vline(xintercept = 0, color = "grey70") +  # Dotted vertical line at x = 0
  
      geom_density(fill = "darkred", alpha = 0.3) + 
    
      geom_vline(xintercept = true_val, 
                 linetype = "dashed", color = "darkred", linewidth=0.8) +  # Dotted vertical line at x = 0
  
        # Crop the axis since model weights are low
      scale_y_continuous(expand = expansion(mult = c(0, 0.05))) + 
    
      scale_x_continuous(limits = c(true_val-0.5, true_val+0.5), expand = c(0,0)) +
    
      labs(y = "", 
           x = "", 
           title = label) +
    
      theme_bw() + 
    
      theme(panel.grid = element_blank())  # Remove background panel grid
})

ggpubr::ggarrange(plotlist = sim_coefficient_plots, ncol = 3, nrow = 3) + 
  bgcolor("white")

ggsave("./figures/top_model_simulations_coefficient_density_reduced_sample_size.png", width = 9, height = 6)
```













