---
title: "Import and explore covariates"
author: "Aidan Brushett"
date: "`r Sys.Date()`"
output: 
  html_document:
    theme: default
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 0. Before you begin

Aidan Brushett M.Sc. Student University of Victoria\
School of Environmental Studies\
Email: [aidanbrushett\@uvic.ca](aidanbrushett@uvic.ca)

------------------------------------------------------------------------

# 1. Setup

```{r}
rm(list=ls()) # start fresh :)

library(tidyverse)
library(ggplot2)
library(writexl)

# These are functions that can sometimes get masked by other packages. Shouldn't be an issue and could be removed.
select <- dplyr::select
filter <- dplyr::filter
mutate <- dplyr::mutate
summarize <- dplyr::summarize
# Cheeky function that means "not in"
`%nin%` = Negate(`%in%`)
```

# 2. Import and merge response variable and covariates

```{r}
response <- read_csv("./data/processed/OSM_monthly_detections_2021_2022_2023.csv") %>%
  
  # remove data for the other species for now
  filter(species == "red squirrel") %>%
  
  select(-species, -presence, "squirrel" = "detections")

covs <- read_csv("./data/processed/OSM_all_covariates_2021_2022_2023.csv") %>%
  
  # remove some configuration metrics that we don't want, plus some others.
  # we don't need anything that describes water/landscape, or these patch measures.
  select(-contains(c("water", "landscape", "lpi", "pd", "np", "core_mn", "area_mn")),
#         -starts_with("anthro"), # remove 'binary' natural cover
#         -starts_with("natural"), # remove'binary' anthro cover
         -lat, -long, -easting_12n, -northing_12n, -buffer_area) %>%
  
  # combine some features a priori
  mutate(seismic = seismic_lines + seismic_lines_3D,
         pipe_trans = transmission_lines + pipeline) %>%
  
  # remove the non-combined features
  select(-pipeline, -transmission_lines, -seismic_lines, -seismic_lines_3D)

# any sites of extra data or covariates?
setdiff(covs$site, response$site)
setdiff(response$site, covs$site)

# Merge into a final data frame
data <- covs %>% 
  
  filter(site %in% response$site) %>%
  
  left_join(response, by = c("site", "array")) %>%
  
  relocate(colnames(response)) 

summary(data)

# clean up
rm(covs, response)
```

Let's handle the NA values for covariates (produced during the extraction process for configuration when a class wasn't present around the camera site). Models won't like this. We cannot simply assign a 0 to these since this is not a meaningful value for all the configuration metrics.

-   `tca` Total core area: can assign a 0
-   `ed` Edge density: can assign a 0
-   `cohesion` Cohesion: can assign a 100 (although I am cautious here, since 100% connectivity is not the same as the class not existing)
-   `split` Splitting index: can assign a 1 (1 effective patch. again, cautious here since 1 effective patch != class not existing)
-   `cai_mn` Mean core area index: can assign a 0 (caution since this means no core area and technically the index here is 0/0 or undefined).

In future, we could remove the NA rows altogether but we would have to be certain to remove the EXACT SAME ROWS from the *NAT* and *COMP* sub-models otherwise our AIC rankings will be inaccurate.

```{r}
summary(data)

# some trends in the forest metrics:
summary(data %>% select(contains("forest")))

data <- data %>%
  mutate(
    across(contains("_tca"), ~ ifelse(is.na(.), 0, .)),
    across(contains("_ed"), ~ ifelse(is.na(.), 0, .)),
    across(contains("_cohesion"), ~ ifelse(is.na(.), 100, .)),
    across(contains("_split"), ~ ifelse(is.na(.), 1, .)),
    across(contains("_cai_mn"), ~ ifelse(is.na(.), 0, .))
  )

summary(data)
```

# 3. Exploratory analysis

Do we have a lot of variation in the data for our covariates? Let's take a look at the 500, 1000, 2500, and 5000 m scale. We have a fuckload of configuration metrics and it would be stupid to explore all of them. For now let's take a look at a few key ones we think might be interesting or useful for our models.

> The following markdown text needs to be re-written once we converge on a final analysis/list of metrics to use

Let's extract:

-   `np` number of patches per landcover type
-   `pd` patch density per 100 Ha per landcover type
-   `area_mn` mean patch area mean area of all patches of a landcover type - many small or few large?
-   `lpi` largest patch index - percent of landscape covered by largest patch, a measure of relative dominance
-   `tca` total core area per landcover type
-   `core_mn` mean core area per patch per landcover type
-   `ed` edge density (edge length in meters per landcover type)
-   `cohesion` connectedness of patches
-   `split` splitting index describing patch size distribution/fragmentation. We will NOT use this since it looks like it did not extract properly.

For a few specific feature types of interest:

-   `anthropogenic` aggregate class of entire human footprint
-   `natural` aggregate class of all non-water landcover
-   `conifer_forest`
-   `broadleaf_forest`
-   `mixed_forest`
-   `seismic` not tca, core_mn, cohesion, split
-   `pipe_trans` not tca, core_mn, cohesion, split
-   `harvest` not tca, core_mn, cohesion, split
-   `wells` not tca, core_mn, cohesion, split
-   `roads` not tca, core_mn, cohesion, split
-   `osm_industrial` not tca, core_mn, cohesion, split

```{r}
# Some metrics we want for basically all of the feature types
#feature_config <- c("anthropogenic", "natural", "coniferous_forest", "broadleaf_forest", 
#                    "mixed_forest", "grassland", "shrubland", "seismic_lines", 
#                    "seismic_lines_3d", "pipeline", "transmission_lines", "wells", 
#                    "harvest", "roads", "osm_industrial")
#metric_config <- c("np", "pd", "area_mn", "lpi", "ed")

#config <- crossing(feature = feature_config, metric = metric_config) %>%
#  mutate(name = str_c(feature, metric, sep = "_")) %>%
#  pull(name)

# Some metrics we want for a subset of the feature types
#feature_config_partial <- c("anthropogenic", "natural", "coniferous_forest", "broadleaf_forest", 
#                           "mixed_forest", "grassland", "shrubland")
#metric_config_partial <- c("tca", "core_mn", "cohesion")

# Collect them all into one list that we can input to 'select'
#config_vars <- c(config, config_partial)

# Some metrics we want for a subset of the feature types
#config_vars <- crossing(feature = c("forest", "nonforest", "veg_anthro", "nonveg_anthro"), 
#                        metric = c("tca", "cai_mn", "ed", "cohesion")) %>%
  
#  mutate(name = str_c(feature, metric, sep = "_")) %>%
  
#  pull(name)

#data <- data_raw %>%
  
#  select(1:48, seismic, pipe_trans, config_vars)
```

Let's look at how much variation we have in our metrics from histograms. For now we'll loop through data that is pooled across all 20 buffer sizes. This is a coarse, for-interest-only tool that we can look at when building the candidate model set.

```{r}
data %>% 
  
  select(6:ncol(.)) %>%
  
  # use imap which will retain both the data (x) and the variable names (y)
  imap(~ ggplot(mapping = aes(x = .x)) +
         geom_histogram(bins = 60, fill = "black", color = "black") +
         labs(title = .y, x = .y, y = "Count") +
         theme_classic())
```

Splitting index does not seem to be a particularly meaningful variable for any of our classes since most values are at or near 1. This indicates that 'fragmentation' *sensu stricto* might not be a particularly prominent ecological mechanism in our study area. Let's remove the splitting index metrics from our dataset to keep things tidy. 

```{r}
data <- data %>%
  
  select(-contains("_split"))
```

Now let's look at correlation among variables. We have a fuck ton of variables to look at so for now we'll export to excel.

```{r}
# Histograms for each buffer size
corr_data <- purrr::map(seq(250, 5000, by = 250), 
                        ~ data %>% 
                          
                          filter(buffer_dist == .x) %>%
                          
                          select(6:ncol(.)) %>%
                          
                          # pairwise complete observations right now since I'm not sure how to manage all the NAs in the configuration metrics yet
                          corrr::correlate(., use = "pairwise.complete.obs", 
                                           method = "pearson", 
                                           diagonal = NA, 
                                           quiet = TRUE) %>%
                          
                          as_tibble() %>%
                          
                          mutate(across(everything(), ~ if_else(row_number() >= min(which(is.na(.))), NA, .))) %>%
                          
                          select(rev(names(.))) %>% 
                          
                          relocate(term)
                        
                        ) %>% 
  
  set_names(paste0(seq(250, 5000, by = 250), "m"))

writexl::write_xlsx(corr_data, "./data/processed/OSM_all_covariates_correlation.xlsx")
```

# 4. Summary table of covariates

This will need to be tweaked at the end of the process to include all variables **at the appropriate spatial scales corresponding to the top results from the dredge**. 

```{r message=FALSE, warning=FALSE}
covariate_table <- data %>%
  
  select(6:ncol(.)) %>%
  
  mutate(across(everything(), ~ replace_na(.x, 0))) %>%
  
  summarise(
    across(everything(), list(
      zmean = ~mean(.),
      zmin = ~min(.),
      zmax = ~max(.),
      zmedian = ~median(.),
      zq20 = ~quantile(., probs = 0.20),
      zq80 = ~quantile(., probs = 0.80)
    ))
  ) %>%
        
  pivot_longer(cols = everything(), names_to = c("Covariate", ".value"), names_sep = "_z") %>%
  
  mutate(`Median (20%, 80%)` = paste0(round(median, 2), 
                                      " (", round(q20, 2), 
                                      "–", 
                                      round(q80, 2), ")"),
         
         `Mean (min, max)` = paste0(round(mean, 2), 
                                    " (", round(min, 2), 
                                    "–", 
                                    round(max, 2), ")"),
         ) %>%
  
  filter(Covariate != 'trails') %>%
  
  select(-mean, -min, -max, -median, -q20, -q80) %>%
  
  mutate(Description = "")

writexl::write_xlsx(covariate_table, "./tables/OSM_all_covariates_summary.xlsx")
```

# 5. Export the dataset!

Let's export the clean, inspected, and reduced data set for analysis in the next script. 

```{r}
write_csv(data, "./data/processed/OSM_monthly_detections_with_covariates_2021_2022_2023.csv")
```

# end script
